{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "END2_06_Encoder_Decoder.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "xVydZmfHF4nG"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojGQm2Xy3wut"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SPhj6gnAnT2"
      },
      "source": [
        "import torch\n",
        "from torchtext.legacy import data\n",
        "from torchtext.legacy import datasets\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "import spacy\n",
        "import pandas as pd \n",
        "import random\n",
        "import os, pickle\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QbT7e4su8vBN"
      },
      "source": [
        "# Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwn4oStE6PzV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0389fd0-dbf9-4b0a-b43f-c6bce216c5a0"
      },
      "source": [
        "# Import and print samples of the dataset\n",
        "path = 'tweets.csv'\n",
        "df = pd.read_csv(path)\n",
        "print(df.head())"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                              tweets  labels\n",
            "0  Obama has called the GOP budget social Darwini...       1\n",
            "1  In his teen years, Obama has been known to use...       0\n",
            "2  IPA Congratulates President Barack Obama for L...       0\n",
            "3  RT @Professor_Why: #WhatsRomneyHiding - his co...       0\n",
            "4  RT @wardollarshome: Obama has approved more ta...       1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "vkssIamdunki",
        "outputId": "022185eb-2f07-4caf-9fea-fc759f9d5fe6"
      },
      "source": [
        "df.iloc[1].tweets"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'In his teen years, Obama has been known to use marijuana and cocaine.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7JdpCW-YbAG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4e20c34-f5c0-4d79-b6b1-31591aaa17ec"
      },
      "source": [
        "print(\"Shape of the data: \", df.shape)\n",
        "print(\"Data value counts:\")\n",
        "print(df.labels.value_counts())"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of the data:  (1364, 2)\n",
            "Data value counts:\n",
            "0    931\n",
            "1    352\n",
            "2     81\n",
            "Name: labels, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBnFDdMLFS16"
      },
      "source": [
        "## Field Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6bKQax2Mf_U"
      },
      "source": [
        "# Define text and target fields of the data\n",
        "Tweet = data.Field(sequential = True,\n",
        "                    tokenize = 'spacy',\n",
        "                    batch_first =True,\n",
        "                    include_lengths=True)\n",
        "\n",
        "Label = data.LabelField(tokenize ='spacy',\n",
        "                        is_target=True,\n",
        "                        batch_first =True,\n",
        "                        sequential =False)\n",
        "\n",
        "fields = [('tweet', Tweet),('label', Label)]"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCMPOnCwFbWA"
      },
      "source": [
        "## Create Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nT-flpH-P1cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b69e0bd-1d92-4bf2-bc97-079b4943cc56"
      },
      "source": [
        "# Creating dataset\n",
        "twitterDataset = data.TabularDataset(path=\"tweets.csv\",\n",
        "                                     format=\"CSV\",\n",
        "                                     fields=fields,\n",
        "                                     skip_header=True)\n",
        "\n",
        "# split the dataset into train and valid\n",
        "(train, valid) = twitterDataset.split(split_ratio=[0.85, 0.15], random_state=random.seed(SEED))\n",
        "\n",
        "print(\"Length of training data: \", len(train))\n",
        "print(\"Length of validation data: \", len(valid))"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of training data:  1159\n",
            "Length of validation data:  205\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUpEOQruR9JL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4719791-2f38-445b-f164-712f0c15166b"
      },
      "source": [
        "# print an example of the dataset\n",
        "print(vars(train.examples[10]))"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'tweet': ['Even', 'CBS', 'wo', \"n't\", 'buy', 'bogus', 'WH', 'explanation', 'of', 'Obama', 'Supreme', 'Court', 'comments', '-', 'at', 'http://t.co/rkNdEmIy', '#', 'withnewt', '#', 'tpn', '#', 'tcot', '#', 'tlot', '#', 'tpp', '#', 'sgp'], 'label': '1'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKdllP3FST4N"
      },
      "source": [
        "## Building Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mx955u93SGeY"
      },
      "source": [
        "MAX_VOCAB_SIZE = 5_000\n",
        "\n",
        "Tweet.build_vocab(train, max_size = MAX_VOCAB_SIZE)\n",
        "Label.build_vocab(train)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rA3tIESdcJdN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "267456e6-b3a2-4512-fe56-070e288acedb"
      },
      "source": [
        "print('Size of input vocab : ', len(Tweet.vocab))\n",
        "print('Size of label vocab : ', len(Label.vocab))\n",
        "print('Top 10 words appreared repeatedly :', list(Tweet.vocab.freqs.most_common(10)))\n",
        "print('Labels : ', Label.vocab.stoi)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of input vocab :  4653\n",
            "Size of label vocab :  3\n",
            "Top 10 words appreared repeatedly : [('Obama', 1064), ('#', 798), (':', 780), ('.', 755), (',', 595), ('\"', 558), ('the', 534), ('RT', 513), ('to', 398), ('?', 392)]\n",
            "Labels :  defaultdict(None, {'0': 0, '1': 1, '2': 2})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqfFUrcfFd3w"
      },
      "source": [
        "## Create iterator objects"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zK2ORoqdTNsM"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "train_iterator, valid_iterator = data.BucketIterator.splits((train, valid),\n",
        "                                                            batch_size = 32, \n",
        "                                                            sort_key = lambda x: len(x.tweet),\n",
        "                                                            sort_within_batch=True,\n",
        "                                                            device = device)"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gg7gTFQO4fby"
      },
      "source": [
        "Save the vocabulary for later use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niE9Cc6-2bD_"
      },
      "source": [
        "with open('tokenizer.pkl', 'wb') as tokens: \n",
        "    pickle.dump(Tweet.vocab.stoi, tokens)"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3vZhdaUFKrp"
      },
      "source": [
        "# Model Building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yGJQAUFFiBO"
      },
      "source": [
        "## Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0qPCWoaF3cP"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    \n",
        "    # Define all the layers used in model\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, n_layers, dropout):        \n",
        "        super().__init__()              \n",
        "\n",
        "        # Embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        # LSTM layer\n",
        "        self.encoder = nn.LSTM(embedding_dim, \n",
        "                           hidden_dim, \n",
        "                           num_layers=n_layers, \n",
        "                           dropout=dropout,\n",
        "                           batch_first=True)\n",
        "        \n",
        "        # Dense layer\n",
        "        # self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "    def forward(self, text, text_lengths, packed_embedded=False, debug=False, print_outputs=False):\n",
        "        if debug:\n",
        "          print(\"\\nBefore entering embedding layer\")\n",
        "          print(\"Text shape: \", text.shape)\n",
        "          print(\"Text length shape: \", text_lengths.shape)\n",
        "          print(\"Text length: \", text_lengths)\n",
        "          \n",
        "        # text = [batch size, text_length]\n",
        "\n",
        "        embedded = self.embedding(text)\n",
        "        # embedded = [batch size, text_length, emb dim]\n",
        "\n",
        "        if packed_embedded:\n",
        "          embedded = pack_padded_sequence(embedded, text_lengths.cpu(), batch_first=True)\n",
        "\n",
        "          if debug:\n",
        "            print(\"packed_embedded shape: \", packed_embedded.data.shape)\n",
        "\n",
        "        output, (hidden, cell) = self.encoder(embedded)\n",
        "        # hidden = [batch size, num layers * num directions, hid dim]\n",
        "        # cell = [batch size, num layers * num directions, hid dim]\n",
        "\n",
        "        encoding = hidden.permute(1, 0, 2)\n",
        "\n",
        "        if debug:\n",
        "          print(\"Embedding shape: \", embedded.shape)\n",
        "          if packed_embedded:\n",
        "            print(\"Output shape: \", output.data.shape)\n",
        "          else:\n",
        "            print(\"Output shape: \", output.shape)    \n",
        "          print(\"Hidden shape: \", hidden.shape)\n",
        "          print(\"Cell shape: \", cell.shape)\n",
        "          print(\"Encoding shape: \", encoding.shape)        \n",
        "\n",
        "        return encoding, (hidden, cell)"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AL-Dk2AddXyK"
      },
      "source": [
        "## Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ez-r5_SOWjs1"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    \n",
        "    # Define all the layers used in model\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, n_layers, dropout):        \n",
        "        super().__init__()     \n",
        "\n",
        "        # LSTM layer\n",
        "        self.decoder = nn.LSTM(input_dim, \n",
        "                           hidden_dim, \n",
        "                           num_layers=n_layers, \n",
        "                           dropout=dropout,\n",
        "                           batch_first=True)\n",
        "        \n",
        "        # Dense layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "    def forward(self, input, hidden_states, debug=False):\n",
        "\n",
        "        if debug:\n",
        "          print(\"\\nBefore entering decoder\")\n",
        "          print(\"Input shape: \", input.shape)\n",
        "          print(\"Hidden states: \", len(hidden_states))\n",
        "\n",
        "        hidden, cell = hidden_states\n",
        "        output, (hidden, cell) = self.decoder(input)\n",
        "        #hidden = [batch size, num layers * num directions,hid dim]\n",
        "        #cell = [batch size, num layers * num directions,hid dim]\n",
        "\n",
        "        if debug:          \n",
        "          print(\"Output shape: \", output.shape)\n",
        "          print(\"Hidden shape: \", hidden.shape)\n",
        "          print(\"Cell shape: \", cell.shape)\n",
        "\n",
        "        dense_outputs = self.fc(hidden[0])\n",
        "        if debug:          \n",
        "          print(\"Dense outputs shape: \", dense_outputs.shape)   \n",
        "            \n",
        "        return dense_outputs"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDQxvaoxbxL4"
      },
      "source": [
        "## Encoder-Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9t1ASPOLb0cS"
      },
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self, encoder, decoder):\n",
        "    super().__init__()\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "\n",
        "  def forward(self, text, text_length):\n",
        "\n",
        "    text, hidden_states = self.encoder(text, text_length)\n",
        "    output = self.decoder(text, hidden_states)\n",
        "\n",
        "    return output"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmJHmzlFftTL"
      },
      "source": [
        "## Create the model object"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3DoppiUdoDU",
        "outputId": "a965ef70-f1f0-4dc8-e8fe-d863619ecf24"
      },
      "source": [
        "N_LAYERS = 1\n",
        "\n",
        "ENC_INPUT_DIM = len(Tweet.vocab)\n",
        "ENC_EMB_DIM = 256\n",
        "ENC_HID_DIM = 25\n",
        "ENC_DROPOUT = 0.2\n",
        "\n",
        "DEC_INPUT_DIM = ENC_HID_DIM\n",
        "DEC_EMB_DIM = ENC_HID_DIM\n",
        "DEC_OUTPUT_DIM = len(Label.vocab)\n",
        "DEC_DROPOUT = 0.2\n",
        "\n",
        "enc = Encoder(ENC_INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
        "dec = Decoder(DEC_INPUT_DIM, DEC_EMB_DIM, DEC_OUTPUT_DIM, N_LAYERS, DEC_DROPOUT)\n",
        "\n",
        "model = Model(enc, dec)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:63: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuLylDLdfEgu",
        "outputId": "46971194-1850-4c1f-def4-a4d2723e37ae"
      },
      "source": [
        "print(model)\n",
        "\n",
        "#No. of trianable parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    \n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model(\n",
            "  (encoder): Encoder(\n",
            "    (embedding): Embedding(4653, 256)\n",
            "    (encoder): LSTM(256, 25, batch_first=True, dropout=0.2)\n",
            "  )\n",
            "  (decoder): Decoder(\n",
            "    (decoder): LSTM(25, 25, batch_first=True, dropout=0.2)\n",
            "    (fc): Linear(in_features=25, out_features=3, bias=True)\n",
            "  )\n",
            ")\n",
            "The model has 1,224,746 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVklO7cTfdst"
      },
      "source": [
        "# define optimizer and loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=2e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Train the model on GPU\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20lBmVlAgaoV"
      },
      "source": [
        "# Train and Test Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owGOwJHhfmhm"
      },
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "    #round predictions to the closest integer\n",
        "    _, predictions = torch.max(preds, 1)\n",
        "    \n",
        "    correct = (predictions == y).float() \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7omhE1Zffmhp"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Retrieve text and no. of words\n",
        "        tweet, tweet_length = batch.tweet\n",
        "\n",
        "        predictions = model(tweet, tweet_length).squeeze(1)\n",
        "        # predictions = model(batch.tweet)\n",
        "        \n",
        "        loss = criterion(predictions, batch.label)\n",
        "        \n",
        "        acc = binary_accuracy(predictions, batch.label)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_DVGvkdfmhu"
      },
      "source": [
        "# Evaluate the model on validation set\n",
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            # Retrieve text and no. of words\n",
        "            tweet, tweet_length = batch.tweet\n",
        "\n",
        "            predictions = model(tweet, tweet_length).squeeze(1)\n",
        "            # predictions = model(batch.tweet)\n",
        "\n",
        "            loss = criterion(predictions, batch.label)\n",
        "            \n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDl2bTMnfmhz"
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZuk3QZDf0E4"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2q6jgIK2fmh1",
        "outputId": "40a1175f-5b07-4713-8862-c44eb9b3ecfe"
      },
      "source": [
        "N_EPOCHS = 15\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "# Model training\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.084 | Train Acc: 55.91%\n",
            "\t Val. Loss: 1.042 |  Val. Acc: 74.11%\n",
            "Epoch: 02 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.054 | Train Acc: 66.00%\n",
            "\t Val. Loss: 0.998 |  Val. Acc: 75.00%\n",
            "Epoch: 03 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 1.025 | Train Acc: 67.77%\n",
            "\t Val. Loss: 0.951 |  Val. Acc: 75.00%\n",
            "Epoch: 04 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.989 | Train Acc: 68.19%\n",
            "\t Val. Loss: 0.901 |  Val. Acc: 75.00%\n",
            "Epoch: 05 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.949 | Train Acc: 67.86%\n",
            "\t Val. Loss: 0.852 |  Val. Acc: 75.00%\n",
            "Epoch: 06 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.908 | Train Acc: 67.86%\n",
            "\t Val. Loss: 0.800 |  Val. Acc: 75.00%\n",
            "Epoch: 07 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.867 | Train Acc: 68.19%\n",
            "\t Val. Loss: 0.760 |  Val. Acc: 75.45%\n",
            "Epoch: 08 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.824 | Train Acc: 69.04%\n",
            "\t Val. Loss: 0.730 |  Val. Acc: 75.45%\n",
            "Epoch: 09 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.784 | Train Acc: 69.21%\n",
            "\t Val. Loss: 0.708 |  Val. Acc: 75.45%\n",
            "Epoch: 10 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.742 | Train Acc: 69.72%\n",
            "\t Val. Loss: 0.693 |  Val. Acc: 75.45%\n",
            "Epoch: 11 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.712 | Train Acc: 72.25%\n",
            "\t Val. Loss: 0.683 |  Val. Acc: 75.45%\n",
            "Epoch: 12 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.687 | Train Acc: 73.68%\n",
            "\t Val. Loss: 0.662 |  Val. Acc: 75.45%\n",
            "Epoch: 13 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.662 | Train Acc: 75.46%\n",
            "\t Val. Loss: 0.642 |  Val. Acc: 76.79%\n",
            "Epoch: 14 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.632 | Train Acc: 77.57%\n",
            "\t Val. Loss: 0.626 |  Val. Acc: 77.23%\n",
            "Epoch: 15 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.599 | Train Acc: 79.01%\n",
            "\t Val. Loss: 0.608 |  Val. Acc: 81.70%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hO8ZPWfTfmh-",
        "outputId": "7737865d-bb2c-460b-de68-3f5ae37e4031"
      },
      "source": [
        "# Model testing\n",
        "model.load_state_dict(torch.load('saved-model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, valid_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.608 | Test Acc: 81.70%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7E6Ke58EID-"
      },
      "source": [
        "# Model Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHXzzC76fmiB"
      },
      "source": [
        "#load weights and tokenizer\n",
        "\n",
        "path='./saved-model.pt'\n",
        "model.load_state_dict(torch.load(path));\n",
        "model.eval();\n",
        "tokenizer_file = open('./tokenizer.pkl', 'rb')\n",
        "tokenizer = pickle.load(tokenizer_file)\n",
        "\n",
        "#inference \n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "def classify_tweet(tweet):\n",
        "    \n",
        "    categories = {0: \"Negative\", 1: \"Positive\", 2: \"Neutral\"}\n",
        "    \n",
        "    # tokenize the tweet \n",
        "    tokenized = [tok.text for tok in nlp.tokenizer(tweet)] \n",
        "    # convert to integer sequence using predefined tokenizer dictionary\n",
        "    indexed = [tokenizer[t] for t in tokenized]        \n",
        "    # compute no. of words        \n",
        "    length = [len(indexed)]\n",
        "    # convert to tensor                                    \n",
        "    tensor = torch.LongTensor(indexed).to(device)   \n",
        "    # reshape in form of batch, no. of words           \n",
        "    tensor = tensor.unsqueeze(1).T  \n",
        "    # convert to tensor                          \n",
        "    length_tensor = torch.LongTensor(length)\n",
        "    # Get the model prediction                 \n",
        "    prediction = model(tensor, length_tensor).squeeze(1)\n",
        "    _, pred = torch.max(prediction, 1) \n",
        "    \n",
        "    return categories[pred.item()]"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "NtsBI6GDfmiD",
        "outputId": "90283d52-f76b-45cb-99cc-ed1fe6ef5d86"
      },
      "source": [
        "classify_tweet(\"In his teen years, Obama has been known to use marijuana and cocaine.\")"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Negative'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzihbQxZD-qD"
      },
      "source": [
        ""
      ],
      "execution_count": 104,
      "outputs": []
    }
  ]
}