{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Session 5_v2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOoqKaAQwsqKU5Z29cmQHDI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SomaKorada07/END2.0/blob/main/Session%205/Session_5_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwA6ZAP0gV57"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "ggimqGoi_BqW",
        "outputId": "864ecdcc-1482-4137-ef52-678a2234b748"
      },
      "source": [
        "df = pd.read_csv('/content/datasetSentences.txt', sep = '\\t', header = 0)\n",
        "df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_index</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Effective but too-tepid biopic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>If you sometimes like to go to the movies to h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Emerges as something rare , an issue movie tha...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentence_index                                           sentence\n",
              "0               1  The Rock is destined to be the 21st Century 's...\n",
              "1               2  The gorgeously elaborate continuation of `` Th...\n",
              "2               3                     Effective but too-tepid biopic\n",
              "3               4  If you sometimes like to go to the movies to h...\n",
              "4               5  Emerges as something rare , an issue movie tha..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiurY2gQK7iI",
        "outputId": "42fca15b-c824-43a6-d6ab-a5eafa6cfcf6"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['sentence_index', 'sentence'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DelWJDZTRyA",
        "outputId": "93c78cc1-672b-4e57-9757-2f4bd9da3d6e"
      },
      "source": [
        "len(df['sentence_index']), len(df['sentence'])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11855, 11855)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "iIJeCQHsTZhQ",
        "outputId": "34c03fd0-fb92-47bb-e0cc-c7a48d9cba6e"
      },
      "source": [
        "df_labels = pd.read_csv('/content/sentiment_labels.txt', sep = '|', header = 0)\n",
        "df_labels.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>phrase ids</th>\n",
              "      <th>sentiment values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.50000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.50000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.44444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.50000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.42708</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   phrase ids  sentiment values\n",
              "0           0           0.50000\n",
              "1           1           0.50000\n",
              "2           2           0.44444\n",
              "3           3           0.50000\n",
              "4           4           0.42708"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eB9MaMYURug",
        "outputId": "44f38cde-a263-469e-c3de-7035884a4f59"
      },
      "source": [
        "len(df_labels)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "239232"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "YBZMpE52U4bO",
        "outputId": "255da538-c311-4ffd-84a0-33e346311e46"
      },
      "source": [
        "df_dict = pd.read_csv('/content/dictionary.txt', sep = '|', header = None)\n",
        "df_dict.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>!</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>! '</td>\n",
              "      <td>22935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>! ''</td>\n",
              "      <td>18235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>! Alas</td>\n",
              "      <td>179257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>! Brilliant</td>\n",
              "      <td>22936</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             0       1\n",
              "0            !       0\n",
              "1          ! '   22935\n",
              "2         ! ''   18235\n",
              "3       ! Alas  179257\n",
              "4  ! Brilliant   22936"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTAZoTo2VtPh",
        "outputId": "3d902a40-bfeb-469d-88e3-6a3a678f7178"
      },
      "source": [
        "df_dict.columns"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Int64Index([0, 1], dtype='int64')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDRsZFU793iO",
        "outputId": "b8d98cea-9f58-49b7-ea69-f580ac7b7b64"
      },
      "source": [
        "type(df_dict[0]), type(df_dict[1])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(pandas.core.series.Series, pandas.core.series.Series)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5iFm-oU_NVc"
      },
      "source": [
        "df_dict.rename(columns = {0: 'phrase', 1: 'phrase ids'}, inplace = True)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1HKRPz1-a5P"
      },
      "source": [
        "# pd.to_numeric(df_dict['phrase ids'], downcast='integer')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "hjG4vzWE-2eu",
        "outputId": "dcaa8a8e-3397-4ece-ffb4-ac52c61cad93"
      },
      "source": [
        "df_dict.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>phrase</th>\n",
              "      <th>phrase ids</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>!</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>! '</td>\n",
              "      <td>22935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>! ''</td>\n",
              "      <td>18235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>! Alas</td>\n",
              "      <td>179257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>! Brilliant</td>\n",
              "      <td>22936</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        phrase  phrase ids\n",
              "0            !           0\n",
              "1          ! '       22935\n",
              "2         ! ''       18235\n",
              "3       ! Alas      179257\n",
              "4  ! Brilliant       22936"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2YC5_s2-4se"
      },
      "source": [
        "df_target = pd.merge(df_labels, df_dict, how = 'inner', left_on = 'phrase ids', right_on = 'phrase ids')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "MQcvoLqRAR9x",
        "outputId": "162b02a6-d242-4ec2-a9db-39faf505a3e8"
      },
      "source": [
        "df_target.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>phrase ids</th>\n",
              "      <th>sentiment values</th>\n",
              "      <th>phrase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.50000</td>\n",
              "      <td>!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.50000</td>\n",
              "      <td>'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.44444</td>\n",
              "      <td>' (</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.50000</td>\n",
              "      <td>' ( the cockettes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.42708</td>\n",
              "      <td>' ( the cockettes )</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   phrase ids  sentiment values               phrase\n",
              "0           0           0.50000                    !\n",
              "1           1           0.50000                    '\n",
              "2           2           0.44444                  ' (\n",
              "3           3           0.50000    ' ( the cockettes\n",
              "4           4           0.42708  ' ( the cockettes )"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIK9S5H7AY8c"
      },
      "source": [
        "common_sentences = df[df['sentence'].isin(df_target['phrase'])]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "5mMH9uladVEQ",
        "outputId": "2405a293-39e9-49af-cabe-1392f853f475"
      },
      "source": [
        "common_sentences"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_index</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Effective but too-tepid biopic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>If you sometimes like to go to the movies to h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Emerges as something rare , an issue movie tha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11850</th>\n",
              "      <td>11851</td>\n",
              "      <td>A real snooze .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11851</th>\n",
              "      <td>11852</td>\n",
              "      <td>No surprises .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11852</th>\n",
              "      <td>11853</td>\n",
              "      <td>We 've seen the hippie-turned-yuppie plot befo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11853</th>\n",
              "      <td>11854</td>\n",
              "      <td>Her fans walked out muttering words like `` ho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11854</th>\n",
              "      <td>11855</td>\n",
              "      <td>In this case zero .</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11286 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       sentence_index                                           sentence\n",
              "0                   1  The Rock is destined to be the 21st Century 's...\n",
              "1                   2  The gorgeously elaborate continuation of `` Th...\n",
              "2                   3                     Effective but too-tepid biopic\n",
              "3                   4  If you sometimes like to go to the movies to h...\n",
              "4                   5  Emerges as something rare , an issue movie tha...\n",
              "...               ...                                                ...\n",
              "11850           11851                                    A real snooze .\n",
              "11851           11852                                     No surprises .\n",
              "11852           11853  We 've seen the hippie-turned-yuppie plot befo...\n",
              "11853           11854  Her fans walked out muttering words like `` ho...\n",
              "11854           11855                                In this case zero .\n",
              "\n",
              "[11286 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URUeg8VRe-l_"
      },
      "source": [
        "def sentence_exists(input_sentence):\n",
        "    matching_phrase = df_target[df_target[\"phrase\"] == input_sentence][\"phrase ids\"].values\n",
        "    default_series = pd.Series({\"phrase ids\":-1000, \"sentiment values\": -1000}) ## For cases where we dont find a full sentence match\n",
        "    if(len(matching_phrase)) > 0:\n",
        "        phrase_id = np.int(matching_phrase[0])\n",
        "        sentiment_value = df_target[df_target[\"phrase ids\"] == matching_phrase[0]][\"sentiment values\"].values[0]\n",
        "        default_series = pd.Series({\"phrase ids\":phrase_id, \"sentiment values\": sentiment_value})\n",
        "\n",
        "    return default_series"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoLGHT5sdWet",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ce3a130-bb8d-47d7-a140-690fdbc9450f"
      },
      "source": [
        "common_sentences.loc[:, [\"phrase ids\", \"sentiment values\"]] =  common_sentences.loc[:,\"sentence\"].apply(sentence_exists)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:659: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self.obj[k] = np.nan\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1715: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  isetter(loc, v)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "reRBbzyjghjN",
        "outputId": "5da9e98a-d256-4b16-9fa2-28f147d252df"
      },
      "source": [
        "common_sentences.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_index</th>\n",
              "      <th>sentence</th>\n",
              "      <th>phrase ids</th>\n",
              "      <th>sentiment values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
              "      <td>226166.0</td>\n",
              "      <td>0.69444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
              "      <td>226300.0</td>\n",
              "      <td>0.83333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Effective but too-tepid biopic</td>\n",
              "      <td>13995.0</td>\n",
              "      <td>0.51389</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>If you sometimes like to go to the movies to h...</td>\n",
              "      <td>14123.0</td>\n",
              "      <td>0.73611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Emerges as something rare , an issue movie tha...</td>\n",
              "      <td>13999.0</td>\n",
              "      <td>0.86111</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentence_index  ... sentiment values\n",
              "0               1  ...          0.69444\n",
              "1               2  ...          0.83333\n",
              "2               3  ...          0.51389\n",
              "3               4  ...          0.73611\n",
              "4               5  ...          0.86111\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAxDwEL7gAws"
      },
      "source": [
        "# pd.to_numeric(common_sentences['phrase ids'], downcast='integer')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "2i9MdAXxhisV",
        "outputId": "5a4fe7b5-9703-4a74-e47e-e3804e7f41ff"
      },
      "source": [
        "common_sentences.head()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_index</th>\n",
              "      <th>sentence</th>\n",
              "      <th>phrase ids</th>\n",
              "      <th>sentiment values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
              "      <td>226166.0</td>\n",
              "      <td>0.69444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
              "      <td>226300.0</td>\n",
              "      <td>0.83333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Effective but too-tepid biopic</td>\n",
              "      <td>13995.0</td>\n",
              "      <td>0.51389</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>If you sometimes like to go to the movies to h...</td>\n",
              "      <td>14123.0</td>\n",
              "      <td>0.73611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Emerges as something rare , an issue movie tha...</td>\n",
              "      <td>13999.0</td>\n",
              "      <td>0.86111</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentence_index  ... sentiment values\n",
              "0               1  ...          0.69444\n",
              "1               2  ...          0.83333\n",
              "2               3  ...          0.51389\n",
              "3               4  ...          0.73611\n",
              "4               5  ...          0.86111\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ny757bpjhkN6",
        "outputId": "02b0b06f-147e-41c1-aa2b-781842724718"
      },
      "source": [
        "common_sentences.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11286, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I23-N6c9UWyW"
      },
      "source": [
        "common_sentences.to_csv(\"CommonSentences.csv\", index=False, sep=\"|\")"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8ddu7a2lgCk"
      },
      "source": [
        "# Training and test dataset\n",
        "After applying above techiniques we get a combined DataFrame that has the following fields:\n",
        "\n",
        "*   sentence_index : Original sentence_index in the datasetSentences.txt\n",
        "*   sentence: The actual sentence\n",
        "*   Phrase_Id: The Phrase_Id used for mapping/retrieving sentiment score\n",
        "*   Sentiment_Score: Actual Sentiment score for the sentence\n",
        "\n",
        "Now we split the DataFrame into Training and Test Dataframes. Note that we are not using the recommended train/ dev /test splits from the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKMNKE38hwHa"
      },
      "source": [
        "train_df = common_sentences.sample(frac = 0.8) \n",
        "test_df = common_sentences[~common_sentences.sentence_index.isin(train_df.sentence_index)]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oQLB7lymZxj",
        "outputId": "b5c6f200-9d8f-4da7-bea3-eced7e10dabd"
      },
      "source": [
        "train_df.shape, test_df.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((9029, 4), (2257, 4))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQBYauo7meTH"
      },
      "source": [
        "train_df.to_csv(\"StanfordTrain.csv\", index=False, sep=\"|\")\n",
        "test_df.to_csv(\"StanfordTest.csv\", index=False, sep=\"|\")"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7uGPt4YqJno"
      },
      "source": [
        "# Data Augmentation Techniques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvTxBI8Pqfhe"
      },
      "source": [
        "##**Back Translation**\n",
        "\n",
        "Another popular approach for augmenting text datasets is back translation. This involves translating a sentence from our target language into one or more other languages and then translating all of them back to the original language. We can use the Python library googletrans for this purpose. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVQTw0IIqzRQ",
        "outputId": "932e8973-51c5-4af1-d345-21513c7e04dd"
      },
      "source": [
        "!pip install googletrans==3.1.0a0"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting googletrans==3.1.0a0\n",
            "  Downloading https://files.pythonhosted.org/packages/19/3d/4e3a1609bf52f2f7b00436cc751eb977e27040665dde2bd57e7152989672/googletrans-3.1.0a0.tar.gz\n",
            "Collecting httpx==0.13.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/b4/698b284c6aed4d7c2b4fe3ba5df1fcf6093612423797e76fbb24890dd22f/httpx-0.13.3-py3-none-any.whl (55kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 5.1MB/s \n",
            "\u001b[?25hCollecting rfc3986<2,>=1.3\n",
            "  Downloading https://files.pythonhosted.org/packages/c4/e5/63ca2c4edf4e00657584608bee1001302bbf8c5f569340b78304f2f446cb/rfc3986-1.5.0-py2.py3-none-any.whl\n",
            "Collecting sniffio\n",
            "  Downloading https://files.pythonhosted.org/packages/52/b0/7b2e028b63d092804b6794595871f936aafa5e9322dcaaad50ebf67445b3/sniffio-1.2.0-py3-none-any.whl\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (3.0.4)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2.10)\n",
            "Collecting hstspreload\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/50/606213e12fb49c5eb667df0936223dcaf461f94e215ea60244b2b1e9b039/hstspreload-2020.12.22-py3-none-any.whl (994kB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 12.5MB/s \n",
            "\u001b[?25hCollecting httpcore==0.9.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/d5/e4ff9318693ac6101a2095e580908b591838c6f33df8d3ee8dd953ba96a8/httpcore-0.9.1-py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2020.12.5)\n",
            "Collecting h2==3.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/de/da019bcc539eeab02f6d45836f23858ac467f584bfec7a526ef200242afe/h2-3.2.0-py2.py3-none-any.whl (65kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 10.5MB/s \n",
            "\u001b[?25hCollecting h11<0.10,>=0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/fd/3dad730b0f95e78aeeb742f96fa7bbecbdd56a58e405d3da440d5bfb90c6/h11-0.9.0-py2.py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.0MB/s \n",
            "\u001b[?25hCollecting hyperframe<6,>=5.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/19/0c/bf88182bcb5dce3094e2f3e4fe20db28a9928cb7bd5b08024030e4b140db/hyperframe-5.2.0-py2.py3-none-any.whl\n",
            "Collecting hpack<4,>=3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/8a/cc/e53517f4a1e13f74776ca93271caef378dadec14d71c61c949d759d3db69/hpack-3.0.0-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: googletrans\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-3.1.0a0-cp37-none-any.whl size=16368 sha256=a08fd3c30c1a045828b077b83dd70745752ed6f8396cb1fc78e2b5bd66c10e0b\n",
            "  Stored in directory: /root/.cache/pip/wheels/27/7a/a0/aff3babbb775549ce6813cb8fa7ff3c0848c4dc62c20f8fdac\n",
            "Successfully built googletrans\n",
            "Installing collected packages: rfc3986, sniffio, hstspreload, hyperframe, hpack, h2, h11, httpcore, httpx, googletrans\n",
            "Successfully installed googletrans-3.1.0a0 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2020.12.22 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 rfc3986-1.5.0 sniffio-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "HV1Hy9zuqocA",
        "outputId": "7deb707b-4bda-4691-f6bd-ad5906dbec36"
      },
      "source": [
        "import random\n",
        "import googletrans\n",
        "#import googletrans.Translator as Translator\n",
        "\n",
        "translator = googletrans.Translator()\n",
        "sentence = ['The dog slept on the rug', 'ran lazily']\n",
        "\n",
        "available_langs = list(googletrans.LANGUAGES.keys()) \n",
        "trans_lang = random.choice(available_langs) \n",
        "print(f\"Translating to {googletrans.LANGUAGES[trans_lang]}\")\n",
        "\n",
        "trans_lang"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Translating to hungarian\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'hu'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sXuwBrqqo3E",
        "outputId": "542b4dee-cd9e-4b68-9853-ea2c062a72d7"
      },
      "source": [
        "sentence = ['The dog slept on the rug']\n",
        "available_langs = list(googletrans.LANGUAGES.keys()) \n",
        "trans_lang = random.choice(available_langs) \n",
        "print(f\"Translating to {googletrans.LANGUAGES[trans_lang]}\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Translating to georgian\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHWkiRkQrIne",
        "outputId": "60b66b2e-252a-4f3e-825b-db54e15766e5"
      },
      "source": [
        "translations = translator.translate(sentence, dest=trans_lang) \n",
        "t_text = [t.text for t in translations]\n",
        "print(t_text)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ძაღლს ხალიჩაზე ეძინა']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjXm8dedrKIk",
        "outputId": "547a9ed5-abe0-40db-ab23-0d14b3df5fb0"
      },
      "source": [
        "translations_en_random = translator.translate(t_text, src=trans_lang, dest='en') \n",
        "en_text = [t.text for t in translations_en_random]\n",
        "print(en_text)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['The dog slept on the carpet']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmEFdQjVrN2T"
      },
      "source": [
        "translator = googletrans.Translator()\n",
        "\n",
        "def back_translate(sentence):\n",
        "    # print(f\"original eng sentence is {sentence}\")\n",
        "    available_langs = list(googletrans.LANGUAGES.keys()) \n",
        "    trans_lang = random.choice(available_langs)\n",
        "    # print(f\"translated lang is {trans_lang}\")\n",
        "    translations = translator.translate(sentence, dest=trans_lang)\n",
        "    t_text = [t.text for t in translations]\n",
        "    # print(f\"translated text is {t_text}\")\n",
        "    translations_en_random = translator.translate(t_text, src=trans_lang, dest='en') \n",
        "    en_text = [t.text for t in translations_en_random]\n",
        "    return en_text"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqVUb6o_rU0z",
        "outputId": "5f316aec-4e2c-4b2f-89e5-4d056fb92a77"
      },
      "source": [
        "back_translate([common_sentences.iloc[0].sentence])"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The cancer is destined to be the new \"Conan\" of the 21st century and he will make a splash even bigger than Arnold Schwarzenegger, Jean-Claude Van Damme or Steven Segal.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdZV_kkSrnRD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpYVYBg9x2C_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVhp-7plyDhO"
      },
      "source": [
        "\n",
        "## **Augmenting with Back_Translate**\n",
        "In this method we make a translate from source English sentence to a sentence in random language and then back into English. We create a dataframe of around 4000 samples and append it back to the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8xXv6kQg8fL",
        "outputId": "29b344b4-244f-47d5-bb79-8ad47adb3e85"
      },
      "source": [
        "train_df.columns.values"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['sentence_index', 'sentence', 'phrase ids', 'sentiment values'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhWaV_yBg18o"
      },
      "source": [
        "simpler_series_df = train_df.copy()\n",
        "empty_series = { col:[] for col in train_df.columns.values}\n",
        "my_new_df = pd.DataFrame(data=empty_series)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "DhDNufdzhCqP",
        "outputId": "bcf838f4-415c-4e41-d3bf-96d6be9f5120"
      },
      "source": [
        "simpler_series_df.head()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_index</th>\n",
              "      <th>sentence</th>\n",
              "      <th>phrase ids</th>\n",
              "      <th>sentiment values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8830</th>\n",
              "      <td>8831</td>\n",
              "      <td>Every so often a movie comes along that confir...</td>\n",
              "      <td>145205.0</td>\n",
              "      <td>0.47222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9897</th>\n",
              "      <td>9898</td>\n",
              "      <td>There 's a neat twist , subtly rendered , that...</td>\n",
              "      <td>188801.0</td>\n",
              "      <td>0.40278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1235</th>\n",
              "      <td>1236</td>\n",
              "      <td>Turns potentially forgettable formula into som...</td>\n",
              "      <td>27089.0</td>\n",
              "      <td>0.75000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1047</th>\n",
              "      <td>1048</td>\n",
              "      <td>The cast is uniformly excellent and relaxed .</td>\n",
              "      <td>26773.0</td>\n",
              "      <td>0.94444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5559</th>\n",
              "      <td>5560</td>\n",
              "      <td>Wonder of wonders -- a teen movie with a human...</td>\n",
              "      <td>111235.0</td>\n",
              "      <td>0.72222</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      sentence_index  ... sentiment values\n",
              "8830            8831  ...          0.47222\n",
              "9897            9898  ...          0.40278\n",
              "1235            1236  ...          0.75000\n",
              "1047            1048  ...          0.94444\n",
              "5559            5560  ...          0.72222\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTzzzEG3hhjg"
      },
      "source": [
        "simpler_series_df[\"sentence_index\"] = simpler_series_df[\"sentence_index\"].astype('int')"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHQ7rksHhkYV"
      },
      "source": [
        "simpler_series_df[\"phrase ids\"] = simpler_series_df[\"phrase ids\"].astype('int')"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "S0i-ThYNhosF",
        "outputId": "f9978972-2950-4f1c-db48-53f7d1ad83ba"
      },
      "source": [
        "simpler_series_df.head()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_index</th>\n",
              "      <th>sentence</th>\n",
              "      <th>phrase ids</th>\n",
              "      <th>sentiment values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8830</th>\n",
              "      <td>8831</td>\n",
              "      <td>Every so often a movie comes along that confir...</td>\n",
              "      <td>145205</td>\n",
              "      <td>0.47222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9897</th>\n",
              "      <td>9898</td>\n",
              "      <td>There 's a neat twist , subtly rendered , that...</td>\n",
              "      <td>188801</td>\n",
              "      <td>0.40278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1235</th>\n",
              "      <td>1236</td>\n",
              "      <td>Turns potentially forgettable formula into som...</td>\n",
              "      <td>27089</td>\n",
              "      <td>0.75000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1047</th>\n",
              "      <td>1048</td>\n",
              "      <td>The cast is uniformly excellent and relaxed .</td>\n",
              "      <td>26773</td>\n",
              "      <td>0.94444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5559</th>\n",
              "      <td>5560</td>\n",
              "      <td>Wonder of wonders -- a teen movie with a human...</td>\n",
              "      <td>111235</td>\n",
              "      <td>0.72222</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      sentence_index  ... sentiment values\n",
              "8830            8831  ...          0.47222\n",
              "9897            9898  ...          0.40278\n",
              "1235            1236  ...          0.75000\n",
              "1047            1048  ...          0.94444\n",
              "5559            5560  ...          0.72222\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pzbCj7zhrJG",
        "outputId": "87cf1e37-e9e8-45e3-ab3d-85c778bba24f"
      },
      "source": [
        "simpler_series_df.shape"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9029, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xK9WK7ufh2m7",
        "outputId": "73ccd00c-e0ff-4a4a-f929-6d99c66da6c2"
      },
      "source": [
        "simpler_series_df[\"sentence_index\"].max()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11855"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vba6uYkiQMu",
        "outputId": "2e95a195-f4dc-46ed-9161-8d60a156f226"
      },
      "source": [
        "my_new_df.shape"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2auxXF5yKLu"
      },
      "source": [
        "max_sentence_ids = simpler_series_df[\"sentence_index\"].max()\n",
        "for idx in simpler_series_df[2000:2500].itertuples():\n",
        "    # print(idx._3)\n",
        "    sentence = idx.sentence\n",
        "    aug_sentence = back_translate([sentence])[0]\n",
        "    max_sentence_ids += 1\n",
        "    simpler_series_df.loc[max_sentence_ids] = [max_sentence_ids, aug_sentence, np.int(idx._3), idx._4]\n",
        "    # print(simpler_series_df.shape)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oCp0xfViLyd",
        "outputId": "6b21554f-e2de-463c-8f81-c8750e597174"
      },
      "source": [
        "simpler_series_df.shape"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9540, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "3gKTttTYntFE",
        "outputId": "fb85d5be-46b1-4cb1-e485-c98d53b15057"
      },
      "source": [
        "simpler_series_df.head(-10)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_index</th>\n",
              "      <th>sentence</th>\n",
              "      <th>phrase ids</th>\n",
              "      <th>sentiment values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8830</th>\n",
              "      <td>8831</td>\n",
              "      <td>Every so often a movie comes along that confir...</td>\n",
              "      <td>145205</td>\n",
              "      <td>0.47222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9897</th>\n",
              "      <td>9898</td>\n",
              "      <td>There 's a neat twist , subtly rendered , that...</td>\n",
              "      <td>188801</td>\n",
              "      <td>0.40278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1235</th>\n",
              "      <td>1236</td>\n",
              "      <td>Turns potentially forgettable formula into som...</td>\n",
              "      <td>27089</td>\n",
              "      <td>0.75000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1047</th>\n",
              "      <td>1048</td>\n",
              "      <td>The cast is uniformly excellent and relaxed .</td>\n",
              "      <td>26773</td>\n",
              "      <td>0.94444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5559</th>\n",
              "      <td>5560</td>\n",
              "      <td>Wonder of wonders -- a teen movie with a human...</td>\n",
              "      <td>111235</td>\n",
              "      <td>0.72222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12859</th>\n",
              "      <td>12859</td>\n",
              "      <td>The noble tradition of men in drag hits an all...</td>\n",
              "      <td>149648</td>\n",
              "      <td>0.20833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12860</th>\n",
              "      <td>12860</td>\n",
              "      <td>Passionate , irrational , long-suffering but c...</td>\n",
              "      <td>46486</td>\n",
              "      <td>0.77778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12861</th>\n",
              "      <td>12861</td>\n",
              "      <td>The way Coppola professes his love for movies ...</td>\n",
              "      <td>26929</td>\n",
              "      <td>0.87500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12862</th>\n",
              "      <td>12862</td>\n",
              "      <td>Adam Sandler is to Gary Cooper what a gnat is ...</td>\n",
              "      <td>143518</td>\n",
              "      <td>0.16667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12863</th>\n",
              "      <td>12863</td>\n",
              "      <td>What might have been readily dismissed as the ...</td>\n",
              "      <td>111035</td>\n",
              "      <td>0.30556</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9530 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       sentence_index  ... sentiment values\n",
              "8830             8831  ...          0.47222\n",
              "9897             9898  ...          0.40278\n",
              "1235             1236  ...          0.75000\n",
              "1047             1048  ...          0.94444\n",
              "5559             5560  ...          0.72222\n",
              "...               ...  ...              ...\n",
              "12859           12859  ...          0.20833\n",
              "12860           12860  ...          0.77778\n",
              "12861           12861  ...          0.87500\n",
              "12862           12862  ...          0.16667\n",
              "12863           12863  ...          0.30556\n",
              "\n",
              "[9530 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjPMvPE5zT_O"
      },
      "source": [
        "simpler_series_df.to_csv(\"StanfordTranslate.csv\", index = False, sep = \"|\")"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knwqd3dgpamH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktrGvZlcpaqE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvfKGoN_qkAR"
      },
      "source": [
        "## **Random Swap**\n",
        "The random swap augmentation takes a sentence and then swaps words within it n times, with each iteration working on the previously swapped sentence. Here we sample two random numbers based on the length of the sentence, and then just keep swapping until we hit n."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xz5AiZgMqk7f"
      },
      "source": [
        "def random_swap(sentence, n=5): \n",
        "    length = range(len(sentence)) \n",
        "    for _ in range(n):\n",
        "        idx1, idx2 = random.sample(length, 2)\n",
        "        sentence[idx1], sentence[idx2] = sentence[idx2], sentence[idx1] \n",
        "    return sentence"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "6gozqUOKrRK_",
        "outputId": "79302dc2-2eb5-4ceb-ace1-0049069dc118"
      },
      "source": [
        "simpler_series_df['sentence'][1]"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"The gorgeously elaborate continuation of `` The Lord of the Rings '' trilogy is so huge that a column of words can not adequately describe co-writer\\\\/director Peter Jackson 's expanded vision of J.R.R. Tolkien 's Middle-earth .\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "uWSKXEZ8rS76",
        "outputId": "568c7f3d-9c9d-4fab-a8b0-b5da735c9774"
      },
      "source": [
        "' '.join(random_swap(simpler_series_df['sentence'][1].split()))"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"words The elaborate continuation of `` gorgeously Lord of the Rings '' trilogy vision so The that a column Jackson huge can not adequately describe co-writer\\\\/director Peter of 's expanded is of J.R.R. Tolkien 's Middle-earth .\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPAZPy7cqlUA"
      },
      "source": [
        "For more on this please go through this [paper](https://arxiv.org/pdf/1901.11196.pdf)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BrnLVhAqJsN"
      },
      "source": [
        "# **Augmenting with Random Swap**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADVBBmnUpawV",
        "outputId": "c5c7051c-28d7-42e7-fab1-11d5e9154870"
      },
      "source": [
        "random_swap_df = simpler_series_df[simpler_series_df['sentence'].str.count('\\s+')>10].sample(frac=0.5)\n",
        "random_swap_df.shape"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3651, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "GsxU_XBvw7dO",
        "outputId": "3f9884d4-07ff-4af6-9709-5f867e4dcfdc"
      },
      "source": [
        "random_swap_df.head(5)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_index</th>\n",
              "      <th>sentence</th>\n",
              "      <th>phrase ids</th>\n",
              "      <th>sentiment values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1215</th>\n",
              "      <td>1216</td>\n",
              "      <td>Far more imaginative and ambitious than the tr...</td>\n",
              "      <td>25291</td>\n",
              "      <td>0.80556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>858</th>\n",
              "      <td>859</td>\n",
              "      <td>Lee Jeong-Hyang tells it so lovingly and films...</td>\n",
              "      <td>25942</td>\n",
              "      <td>0.79167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3404</th>\n",
              "      <td>3405</td>\n",
              "      <td>Sayles is making a statement about the inabili...</td>\n",
              "      <td>68609</td>\n",
              "      <td>0.55556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2583</th>\n",
              "      <td>2584</td>\n",
              "      <td>`` Me Without You '' is a probing examination ...</td>\n",
              "      <td>227532</td>\n",
              "      <td>0.58333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8819</th>\n",
              "      <td>8820</td>\n",
              "      <td>To enjoy this movie 's sharp dialogue and deli...</td>\n",
              "      <td>150388</td>\n",
              "      <td>0.59722</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      sentence_index  ... sentiment values\n",
              "1215            1216  ...          0.80556\n",
              "858              859  ...          0.79167\n",
              "3404            3405  ...          0.55556\n",
              "2583            2584  ...          0.58333\n",
              "8819            8820  ...          0.59722\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5X2XjWympa1j"
      },
      "source": [
        "random_swap_df['sentence'] = random_swap_df.sentence.str.split().apply(random_swap).apply(' '.join)"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "MJyaVkQspa3-",
        "outputId": "45a7201e-b38c-4ca7-c146-12903f95e172"
      },
      "source": [
        "random_swap_df.head(5)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_index</th>\n",
              "      <th>sentence</th>\n",
              "      <th>phrase ids</th>\n",
              "      <th>sentiment values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1215</th>\n",
              "      <td>1216</td>\n",
              "      <td>Far more imaginative ambitious made animated t...</td>\n",
              "      <td>25291</td>\n",
              "      <td>0.80556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>858</th>\n",
              "      <td>859</td>\n",
              "      <td>and Jeong-Hyang tells it beautifully lovingly ...</td>\n",
              "      <td>25942</td>\n",
              "      <td>0.79167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3404</th>\n",
              "      <td>3405</td>\n",
              "      <td>Sayles is making forward statement a generatio...</td>\n",
              "      <td>68609</td>\n",
              "      <td>0.55556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2583</th>\n",
              "      <td>2584</td>\n",
              "      <td>decades a Without You '' is a probing . of aga...</td>\n",
              "      <td>227532</td>\n",
              "      <td>0.58333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8819</th>\n",
              "      <td>8820</td>\n",
              "      <td>To sense this movie delightful sharp dialogue ...</td>\n",
              "      <td>150388</td>\n",
              "      <td>0.59722</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      sentence_index  ... sentiment values\n",
              "1215            1216  ...          0.80556\n",
              "858              859  ...          0.79167\n",
              "3404            3405  ...          0.55556\n",
              "2583            2584  ...          0.58333\n",
              "8819            8820  ...          0.59722\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5GdLJh_xEDF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oG_p9rWXxEHL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUu4EJDkxNJy"
      },
      "source": [
        "# **Random Deletion**\n",
        "As the name suggests, random deletion deletes words from a sentence. Given a probability parameter p, it will go through the sentence and decide whether to delete a word or not based on that random probability. Consider of it as pixel dropouts while treating images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3jJX-YnxEKk"
      },
      "source": [
        "def random_deletion(words, p=0.5): \n",
        "    # if len(words) == 1: # return if single word\n",
        "    #     return words\n",
        "    remaining = list(filter(lambda x: random.uniform(0,1) > p,words)) \n",
        "    if len(remaining) == 0: # if not left, sample a random word\n",
        "        return [random.choice(words)] \n",
        "    else:\n",
        "        return remaining"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2nJjN-RxUJN",
        "outputId": "2b5b382c-55a7-4a69-fca7-7ba33bc63f7d"
      },
      "source": [
        "random_deletion_df = simpler_series_df[simpler_series_df['sentence'].str.count('\\s+')>10].sample(frac=0.5)\n",
        "random_deletion_df.shape"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3651, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "WKnjH0G7xUMg",
        "outputId": "ce43489c-a2b8-4593-dcc9-75ac40224e73"
      },
      "source": [
        "random_deletion_df.head()"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_index</th>\n",
              "      <th>sentence</th>\n",
              "      <th>phrase ids</th>\n",
              "      <th>sentiment values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2149</th>\n",
              "      <td>2150</td>\n",
              "      <td>A winning piece of work filled with love for t...</td>\n",
              "      <td>44342</td>\n",
              "      <td>0.791670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4887</th>\n",
              "      <td>4888</td>\n",
              "      <td>You can fire a torpedo through some of Clancy ...</td>\n",
              "      <td>111337</td>\n",
              "      <td>0.166670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5323</th>\n",
              "      <td>5324</td>\n",
              "      <td>Saved from being merely way-cool by a basic , ...</td>\n",
              "      <td>108769</td>\n",
              "      <td>0.486110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6155</th>\n",
              "      <td>6156</td>\n",
              "      <td>... while certainly clever in spots , this too...</td>\n",
              "      <td>103256</td>\n",
              "      <td>0.277780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9714</th>\n",
              "      <td>9715</td>\n",
              "      <td>This is the kind of movie that you only need t...</td>\n",
              "      <td>189034</td>\n",
              "      <td>0.097222</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      sentence_index  ... sentiment values\n",
              "2149            2150  ...         0.791670\n",
              "4887            4888  ...         0.166670\n",
              "5323            5324  ...         0.486110\n",
              "6155            6156  ...         0.277780\n",
              "9714            9715  ...         0.097222\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "SRBEN9-LxUP6",
        "outputId": "1a9ad68a-c776-457d-cff3-9642e50c142f"
      },
      "source": [
        "random_deletion_df['sentence'] = random_deletion_df.sentence.str.split().apply(random_deletion).apply(' '.join)\n",
        "random_deletion_df.head(5)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_index</th>\n",
              "      <th>sentence</th>\n",
              "      <th>phrase ids</th>\n",
              "      <th>sentiment values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2149</th>\n",
              "      <td>2150</td>\n",
              "      <td>A the movies the .</td>\n",
              "      <td>44342</td>\n",
              "      <td>0.791670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4887</th>\n",
              "      <td>4888</td>\n",
              "      <td>torpedo of holes scripters deserve Oscars</td>\n",
              "      <td>111337</td>\n",
              "      <td>0.166670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5323</th>\n",
              "      <td>5324</td>\n",
              "      <td>from being .</td>\n",
              "      <td>108769</td>\n",
              "      <td>0.486110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6155</th>\n",
              "      <td>6156</td>\n",
              "      <td>... clever in this update Macbeth of</td>\n",
              "      <td>103256</td>\n",
              "      <td>0.277780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9714</th>\n",
              "      <td>9715</td>\n",
              "      <td>the of you to watch for before you yourself , ...</td>\n",
              "      <td>189034</td>\n",
              "      <td>0.097222</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      sentence_index  ... sentiment values\n",
              "2149            2150  ...         0.791670\n",
              "4887            4888  ...         0.166670\n",
              "5323            5324  ...         0.486110\n",
              "6155            6156  ...         0.277780\n",
              "9714            9715  ...         0.097222\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9S_qCydxEOA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbXOj7uvzirj"
      },
      "source": [
        "final_train_df = pd.concat([simpler_series_df, random_deletion_df, random_swap_df], axis=0).reset_index(drop=True)"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfUPXdYHzlwu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0772bd5f-7e08-449c-c89b-8d7f7b053ef1"
      },
      "source": [
        "final_train_df.shape"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16842, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEVIWiQryCKO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6ZPA28XyCNp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wN4W9Q7zoGD"
      },
      "source": [
        "## **Range expansion**\n",
        "The sentiment scores are floats between [0,1] so we convert this to equivalent integers between 0 and 24(i.e 25 different classes)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZnU3NYWztsO"
      },
      "source": [
        "final_train_df[\"label\"] = 0\n",
        "\n",
        "# def quantize_predictions(score_val):\n",
        "#     return np.floor(score_val * 24)\n",
        "\n",
        "def quantize_predictions(score_val):\n",
        "    if(score_val >=0 and score_val <=0.2):\n",
        "        return 0\n",
        "    if(score_val > 0.2 and score_val <=0.4):\n",
        "        return 1\n",
        "    if(score_val > 0.4 and score_val <=0.6):\n",
        "        return 2\n",
        "    if(score_val > 0.6 and score_val <=0.8):\n",
        "        return 3\n",
        "    if(score_val > 0.8 and score_val <=1):\n",
        "        return 4\n",
        "\n",
        "final_train_df.loc[:,\"label\"] = final_train_df.loc[:,\"sentiment values\"].apply(quantize_predictions)"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2z5z-yk_z8e-"
      },
      "source": [
        "final_train_df[\"sentence_index\"] = final_train_df[\"sentence_index\"].astype('int')\n",
        "final_train_df[\"phrase ids\"] = final_train_df[\"phrase ids\"].astype('int')\n",
        "final_train_df[\"label\"] = final_train_df[\"label\"].astype('int')"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "kgwaRagM0Lqk",
        "outputId": "2497bb5a-29c4-41a4-e0aa-a193feced6ff"
      },
      "source": [
        "final_train_df"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_index</th>\n",
              "      <th>sentence</th>\n",
              "      <th>phrase ids</th>\n",
              "      <th>sentiment values</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8831</td>\n",
              "      <td>Every so often a movie comes along that confir...</td>\n",
              "      <td>145205</td>\n",
              "      <td>0.47222</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9898</td>\n",
              "      <td>There 's a neat twist , subtly rendered , that...</td>\n",
              "      <td>188801</td>\n",
              "      <td>0.40278</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1236</td>\n",
              "      <td>Turns potentially forgettable formula into som...</td>\n",
              "      <td>27089</td>\n",
              "      <td>0.75000</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1048</td>\n",
              "      <td>The cast is uniformly excellent and relaxed .</td>\n",
              "      <td>26773</td>\n",
              "      <td>0.94444</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5560</td>\n",
              "      <td>Wonder of wonders -- a teen movie with a human...</td>\n",
              "      <td>111235</td>\n",
              "      <td>0.72222</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16837</th>\n",
              "      <td>5271</td>\n",
              "      <td>Those who do Godard entirely ` get ' of 's exi...</td>\n",
              "      <td>110590</td>\n",
              "      <td>0.66667</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16838</th>\n",
              "      <td>2067</td>\n",
              "      <td>gives consideration murderer Director Dahmer ....</td>\n",
              "      <td>45070</td>\n",
              "      <td>0.55556</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16839</th>\n",
              "      <td>4731</td>\n",
              "      <td>You come away from , overwhelmed perhaps his f...</td>\n",
              "      <td>111346</td>\n",
              "      <td>0.73611</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16840</th>\n",
              "      <td>3888</td>\n",
              "      <td>, strong inescapably A and absolutely , amazin...</td>\n",
              "      <td>63427</td>\n",
              "      <td>0.88889</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16841</th>\n",
              "      <td>9806</td>\n",
              "      <td>kids of those films where the characters inhab...</td>\n",
              "      <td>186576</td>\n",
              "      <td>0.23611</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16842 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       sentence_index  ... label\n",
              "0                8831  ...     2\n",
              "1                9898  ...     2\n",
              "2                1236  ...     3\n",
              "3                1048  ...     4\n",
              "4                5560  ...     3\n",
              "...               ...  ...   ...\n",
              "16837            5271  ...     3\n",
              "16838            2067  ...     2\n",
              "16839            4731  ...     3\n",
              "16840            3888  ...     4\n",
              "16841            9806  ...     1\n",
              "\n",
              "[16842 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aw1MNfvk0oh4"
      },
      "source": [
        "final_train_df.to_csv(\"StanFullTrain.csv\", index = False, sep = \"|\")"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUgfDZuM0pOi"
      },
      "source": [
        "## **Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7F0WxI240xLt",
        "outputId": "ed049d07-17c1-475b-9956-2609498bf06a"
      },
      "source": [
        "# Import Library\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import torch, torchtext\n",
        "from torchtext.legacy import data\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Manual Seed\n",
        "SEED = 43\n",
        "torch.manual_seed(SEED)"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fc398aca2f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sxPzjmb0996"
      },
      "source": [
        "final_train_df = pd.read_csv(\"StanFullTrain.csv\", sep=\"|\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "etsp9N790_qq",
        "outputId": "183bc41d-0f4a-4169-f342-3d5b9519ab4f"
      },
      "source": [
        "num_bins = 5\n",
        "\n",
        "colors = ['green'] \n",
        "plt.hist(final_train_df.label, density = False, bins = 5, histtype = 'bar', color = colors, label = colors)"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([2123., 4414., 3164., 4526., 2615.]),\n",
              " array([0. , 0.8, 1.6, 2.4, 3.2, 4. ]),\n",
              " <a list of 5 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAPAklEQVR4nO3dcayddX3H8ffHFtDEzaK9YaTtLItNlrpMZU2tMVkMRKhoKIloajathqXJxjLNljjxj3WoJPqPOLepIdKsOicQNKMjGNMAxuwPwSKIAmNcdYY2aCuFqnGyFL/74/zKTq739p5Lzz3ndr/3Kzm5z/N7fud5vs+vfT7nuc95zrmpKiRJfXjBtAuQJE2OoS9JHTH0Jakjhr4kdcTQl6SOrJ52Aaeydu3a2rhx47TLkKQzyn333feTqpqZb9mKDv2NGzdy8ODBaZchSWeUJD9caJmXdySpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSMr+hO5kn5drs20S5i42uMfexoXz/QlqSOGviR1xNCXpI4Y+pLUEd/I/X/EN/gkLcYzfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjoycugnWZXk/iS3t/kLktyTZDbJzUnObu3ntPnZtnzj0Dquae2PJrl03DsjSTq1pZzpvxd4ZGj+Y8D1VfUK4CngqtZ+FfBUa7++9SPJZmAn8EpgO/CpJKtOr3xJ0lKMFPpJ1gNvBj7b5gNcBNzauuwDrmjTO9o8bfnFrf8O4KaqeqaqfgDMAlvHsROSpNGMeqb/CeD9wK/a/MuAp6vqRJs/BKxr0+uAxwHa8uOt/3Pt8zznOUl2JzmY5ODRo0eXsCuSpMUsGvpJ3gIcqar7JlAPVXVDVW2pqi0zMzOT2KQkdWOUP4z+euDyJJcBLwR+E/g7YE2S1e1sfj1wuPU/DGwADiVZDbwEeHKo/aTh50iSJmDRM/2quqaq1lfVRgZvxN5VVX8E3A1c2brtAm5r0/vbPG35XVVVrX1nu7vnAmATcO/Y9kSStKhRzvQX8tfATUk+AtwP3NjabwQ+n2QWOMbghYKqeijJLcDDwAng6qp69jS2L0laoiWFflV9Dfham/4+89x9U1W/BN62wPOvA65bapGSpPHwE7mS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0JekjqyedgHS6ci1mXYJ0hnFM31J6oihL0kdMfQlqSOLhn6SFya5N8m3kzyU5NrWfkGSe5LMJrk5ydmt/Zw2P9uWbxxa1zWt/dEkly7XTkmS5jfKmf4zwEVV9Srg1cD2JNuAjwHXV9UrgKeAq1r/q4CnWvv1rR9JNgM7gVcC24FPJVk1zp2RJJ3aoqFfAz9vs2e1RwEXAbe29n3AFW16R5unLb84SVr7TVX1TFX9AJgFto5lLyRJIxnpmn6SVUkeAI4AB4DvAU9X1YnW5RCwrk2vAx4HaMuPAy8bbp/nOZKkCRgp9Kvq2ap6NbCewdn57y5XQUl2JzmY5ODRo0eXazOS1KUl3b1TVU8DdwOvA9YkOfnhrvXA4TZ9GNgA0Ja/BHhyuH2e5wxv44aq2lJVW2ZmZpZSniRpEaPcvTOTZE2bfhHwRuARBuF/Zeu2C7itTe9v87Tld1VVtfad7e6eC4BNwL3j2hFJ0uJG+RqG84F97U6bFwC3VNXtSR4GbkryEeB+4MbW/0bg80lmgWMM7tihqh5KcgvwMHACuLqqnh3v7kiSTmXR0K+qB4HXzNP+fea5+6aqfgm8bYF1XQdct/QyJUnj4CdyJakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktSRUb5lU5KmKtdm2iVMXO2pZVmvZ/qS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjq6ddwHLKtZl2CZK0onimL0kdWTT0k2xIcneSh5M8lOS9rf2lSQ4keaz9PLe1J8knk8wmeTDJhUPr2tX6P5Zk1/LtliRpPqOc6Z8A/qqqNgPbgKuTbAY+ANxZVZuAO9s8wJuATe2xG/g0DF4kgD3Aa4GtwJ6TLxSSpMlYNPSr6omq+lab/hnwCLAO2AHsa932AVe06R3A52rgG8CaJOcDlwIHqupYVT0FHAC2j3VvJEmntKRr+kk2Aq8B7gHOq6on2qIfAee16XXA40NPO9TaFmqfu43dSQ4mOXj06NGllCdJWsTIoZ/kxcCXgPdV1U+Hl1VVATWOgqrqhqraUlVbZmZmxrFKSVIzUugnOYtB4H+hqr7cmn/cLtvQfh5p7YeBDUNPX9/aFmqXJE3IKHfvBLgReKSqPj60aD9w8g6cXcBtQ+3vanfxbAOOt8tAXwUuSXJuewP3ktYmSZqQUT6c9XrgncB3kjzQ2j4IfBS4JclVwA+Bt7dldwCXAbPAL4D3AFTVsSQfBr7Z+n2oqo6NZS8kSSNZNPSr6t+BhT7aevE8/Qu4eoF17QX2LqVASdL4+IlcSeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjiwa+kn2JjmS5LtDbS9NciDJY+3nua09ST6ZZDbJg0kuHHrOrtb/sSS7lmd3JEmnMsqZ/j8B2+e0fQC4s6o2AXe2eYA3AZvaYzfwaRi8SAB7gNcCW4E9J18oJEmTs2joV9XXgWNzmncA+9r0PuCKofbP1cA3gDVJzgcuBQ5U1bGqego4wK+/kEiSltnzvaZ/XlU90aZ/BJzXptcBjw/1O9TaFmr/NUl2JzmY5ODRo0efZ3mSpPmc9hu5VVVAjaGWk+u7oaq2VNWWmZmZca1WksTzD/0ft8s2tJ9HWvthYMNQv/WtbaF2SdIEPd/Q3w+cvANnF3DbUPu72l0824Dj7TLQV4FLkpzb3sC9pLVJkiZo9WIdknwReAOwNskhBnfhfBS4JclVwA+Bt7fudwCXAbPAL4D3AFTVsSQfBr7Z+n2oqua+OSxJWmaLhn5VvWOBRRfP07eAqxdYz15g75KqkySNlZ/IlaSOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6sjEQz/J9iSPJplN8oFJb1+SejbR0E+yCvhH4E3AZuAdSTZPsgZJ6tmkz/S3ArNV9f2q+h/gJmDHhGuQpG6tnvD21gGPD80fAl473CHJbmB3m/15kkdPY3trgZ+cxvOXi3UtjXUtjXUtzYqsK3+b06nr5QstmHToL6qqbgBuGMe6khysqi3jWNc4WdfSWNfSWNfS9FbXpC/vHAY2DM2vb22SpAmYdOh/E9iU5IIkZwM7gf0TrkGSujXRyztVdSLJnwNfBVYBe6vqoWXc5FguEy0D61oa61oa61qarupKVS3HeiVJK5CfyJWkjhj6ktSRMz70F/tahyTnJLm5Lb8nycYVUte7kxxN8kB7/MmE6tqb5EiS7y6wPEk+2ep+MMmFK6SuNyQ5PjRefzOhujYkuTvJw0keSvLeefpMfMxGrGviY5bkhUnuTfLtVte18/SZ+DE5Yl3TOiZXJbk/ye3zLBv/WFXVGftg8Gbw94DfAc4Gvg1sntPnz4DPtOmdwM0rpK53A/8whTH7Q+BC4LsLLL8M+AoQYBtwzwqp6w3A7VMYr/OBC9v0bwD/Oc+/5cTHbMS6Jj5mbQxe3KbPAu4Bts3pM41jcpS6pnVM/iXwL/P9Wy3HWJ3pZ/qjfK3DDmBfm74VuDhJVkBdU1FVXweOnaLLDuBzNfANYE2S81dAXVNRVU9U1bfa9M+ARxh8snzYxMdsxLomro3Bz9vsWe0x926RiR+TI9Y1cUnWA28GPrtAl7GP1Zke+vN9rcPc//jP9amqE8Bx4GUroC6At7bLAbcm2TDP8mkYtfZpeF379fwrSV456Y23X61fw+AscdhUx+wUdcEUxqxdrngAOAIcqKoFx2uCx+QodcHkj8lPAO8HfrXA8rGP1Zke+meyfwM2VtXvAwf4v1dzze9bwMur6lXA3wP/OsmNJ3kx8CXgfVX100lu+1QWqWsqY1ZVz1bVqxl84n5rkt+bxHYXM0JdEz0mk7wFOFJV9y3nduY600N/lK91eK5PktXAS4Anp11XVT1ZVc+02c8Cf7DMNY1qRX5VRlX99OSv51V1B3BWkrWT2HaSsxgE6xeq6svzdJnKmC1W1zTHrG3zaeBuYPucRdM4JhetawrH5OuBy5P8F4NLwBcl+ec5fcY+Vmd66I/ytQ77gV1t+krgrmrvikyzrjnXfC9ncE12JdgPvKvdkbINOF5VT0y7qCS/dfJaZpKtDP7vLntQtG3eCDxSVR9foNvEx2yUuqYxZklmkqxp0y8C3gj8x5xuEz8mR6lr0sdkVV1TVeuraiODjLirqv54Trexj9WK+5bNpagFvtYhyYeAg1W1n8GB8fkkswzeKNy5Qur6iySXAydaXe9e7roAknyRwV0da5McAvYweFOLqvoMcAeDu1FmgV8A71khdV0J/GmSE8B/Azsn8OINg7OxdwLfadeDAT4I/PZQbdMYs1HqmsaYnQ/sy+APJr0AuKWqbp/2MTliXVM5Juda7rHyaxgkqSNn+uUdSdISGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI/8Lj39lgndx0YkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBwnCl821V9q"
      },
      "source": [
        "Sentence = data.Field(sequential = True, tokenize = 'spacy', batch_first =True, include_lengths=True)\n",
        "Label = data.LabelField(tokenize ='spacy', is_target=True, batch_first =True, sequential =False)"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALVglAZ71Y-7"
      },
      "source": [
        "fields = [('sentence', Sentence),('label',Label)]"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4pUzcwQ1bRi"
      },
      "source": [
        "example = [data.Example.fromlist([final_train_df.sentence[i],final_train_df.label[i]], fields) for i in range(final_train_df.shape[0])] \n",
        "\n",
        "stanTreeDataset = data.Dataset(example, fields)\n",
        "(train, valid) = stanTreeDataset.split(split_ratio=[0.85, 0.15], random_state=random.seed(SEED))\n",
        "Sentence.build_vocab(train)\n",
        "Label.build_vocab(train)"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwQMYfPF1fGB",
        "outputId": "f86b55e3-cce7-4f48-cb3f-2a56d93ba149"
      },
      "source": [
        "(len(train), len(valid))"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14316, 2526)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LddtK8AX1h7-",
        "outputId": "a75e957a-bace-4359-85df-e41628f6adb5"
      },
      "source": [
        "print('Size of input vocab : ', len(Sentence.vocab))\n",
        "print('Size of label vocab : ', len(Label.vocab))\n",
        "print('Top 10 words appreared repeatedly :', list(Sentence.vocab.freqs.most_common(10)))\n",
        "print('Labels : ', Label.vocab.stoi)"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of input vocab :  16892\n",
            "Size of label vocab :  5\n",
            "Top 10 words appreared repeatedly : [('.', 12104), (',', 11381), ('the', 9825), ('of', 7142), ('a', 6980), ('and', 6976), ('to', 5011), ('-', 4318), ('is', 3948), (\"'s\", 3944)]\n",
            "Labels :  defaultdict(None, {3: 0, 1: 1, 2: 2, 4: 3, 0: 4})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbQ2f7Al1kN1"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBz9dcf81mSR"
      },
      "source": [
        "train_iterator, valid_iterator = data.BucketIterator.splits((train, valid), batch_size = 32, \n",
        "                                                            sort_key = lambda x: len(x.sentence),\n",
        "                                                            sort_within_batch=True, device = device)"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EOcbV8L1ouJ",
        "outputId": "0742c8b2-424b-42a7-fb91-3f177c06e978"
      },
      "source": [
        "next(iter(train_iterator))"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[torchtext.legacy.data.batch.Batch of size 32]\n",
              "\t[.sentence]:('[torch.cuda.LongTensor of size 32x26 (GPU 0)]', '[torch.cuda.LongTensor of size 32 (GPU 0)]')\n",
              "\t[.label]:[torch.cuda.LongTensor of size 32 (GPU 0)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YspsraVl1reJ"
      },
      "source": [
        "import os, pickle\n",
        "with open('tokenizer.pkl', 'wb') as tokens: \n",
        "    pickle.dump(Sentence.vocab.stoi, tokens)"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUdVyUS21xc5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oNu49KiUAFuL"
      },
      "source": [
        "## **Model Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7YOPNmaAJRo"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class classifier(nn.Module):\n",
        "    \n",
        "    # Define all the layers used in model\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, dropout):\n",
        "        \n",
        "        super().__init__()          \n",
        "        \n",
        "        # Embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        \n",
        "        # LSTM layer\n",
        "        self.encoder = nn.LSTM(embedding_dim, \n",
        "                           hidden_dim, \n",
        "                           num_layers=n_layers, \n",
        "                           dropout=dropout,\n",
        "                           batch_first=True)\n",
        "        # try using nn.GRU or nn.RNN here and compare their performances\n",
        "        # try bidirectional and compare their performances\n",
        "        \n",
        "        # Dense layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "    def forward(self, text, text_lengths):\n",
        "        \n",
        "        # text = [batch size, sent_length]\n",
        "        embedded = self.embedding(text)\n",
        "        # embedded = [batch size, sent_len, emb dim]\n",
        "      \n",
        "        # packed sequence\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.cpu(), batch_first=True)\n",
        "        \n",
        "        packed_output, (hidden, cell) = self.encoder(packed_embedded)\n",
        "        #hidden = [batch size, num layers * num directions,hid dim]\n",
        "        #cell = [batch size, num layers * num directions,hid dim]\n",
        "    \n",
        "        # Hidden = [batch size, hid dim * num directions]\n",
        "        dense_outputs = self.fc(hidden)   \n",
        "        \n",
        "        # Final activation function softmax\n",
        "        output = F.softmax(dense_outputs[0], dim=1)\n",
        "            \n",
        "        return output"
      ],
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAq5sCSvAKd1"
      },
      "source": [
        "# Define hyperparameters\n",
        "size_of_vocab = len(Sentence.vocab)\n",
        "embedding_dim = 300\n",
        "num_hidden_nodes = 100\n",
        "num_output_nodes = len(final_train_df.label.unique())\n",
        "num_layers = 2\n",
        "dropout = 0.2\n",
        "\n",
        "# Instantiate the model\n",
        "model = classifier(size_of_vocab, embedding_dim, num_hidden_nodes, num_output_nodes, num_layers, dropout = dropout)"
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgG8C_bFAMkl",
        "outputId": "74b0b22e-73c6-4e64-8487-922373d8a618"
      },
      "source": [
        "print(model)\n",
        "\n",
        "#No. of trianable parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    \n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "classifier(\n",
            "  (embedding): Embedding(16892, 300)\n",
            "  (encoder): LSTM(300, 100, num_layers=2, batch_first=True, dropout=0.2)\n",
            "  (fc): Linear(in_features=100, out_features=5, bias=True)\n",
            ")\n",
            "The model has 5,309,705 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdqBf8dDAN-l"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# define optimizer and loss\n",
        "optimizer = optim.Adam(model.parameters(), lr=2e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# define metric\n",
        "def binary_accuracy(preds, y):\n",
        "    #round predictions to the closest integer\n",
        "    _, predictions = torch.max(preds, 1)\n",
        "    \n",
        "    correct = (predictions == y).float() \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc\n",
        "    \n",
        "# push to cuda if available\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FopJSB4TAPwU"
      },
      "source": [
        ""
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MOMojDwASLh"
      },
      "source": [
        "## **Model Training & Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmmzRJBKAWAJ"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    # initialize every epoch \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    # set the model in training phase\n",
        "    model.train()  \n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        # resets the gradients after every batch\n",
        "        optimizer.zero_grad()   \n",
        "        \n",
        "        # retrieve text and no. of words\n",
        "        sentence, sentence_lengths = batch.sentence\n",
        "        \n",
        "        # convert to 1D tensor\n",
        "        predictions = model(sentence, sentence_lengths).squeeze()  \n",
        "        #print(predictions)\n",
        "        # compute the loss\n",
        "        loss = criterion(predictions, batch.label)        \n",
        "        \n",
        "        # compute the binary accuracy\n",
        "        acc = binary_accuracy(predictions, batch.label)   \n",
        "        \n",
        "        # backpropage the loss and compute the gradients\n",
        "        loss.backward()       \n",
        "        \n",
        "        # update the weights\n",
        "        optimizer.step()      \n",
        "        \n",
        "        # loss and accuracy\n",
        "        epoch_loss += loss.item()  \n",
        "        epoch_acc += acc.item()    \n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TM5cNegKAWyF"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    # initialize every epoch\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "\n",
        "    # deactivating dropout layers\n",
        "    model.eval()\n",
        "    \n",
        "    # deactivates autograd\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "        \n",
        "            # retrieve text and no. of words\n",
        "            sentence, sentence_lengths = batch.sentence\n",
        "            \n",
        "            # convert to 1d tensor\n",
        "            predictions = model(sentence, sentence_lengths).squeeze()\n",
        "            #print(predictions)\n",
        "            \n",
        "            # compute loss and accuracy\n",
        "            loss = criterion(predictions, batch.label)\n",
        "            acc = binary_accuracy(predictions, batch.label)\n",
        "            \n",
        "            # keep track of loss and accuracy\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6xxtUijAjEo",
        "outputId": "3e16e58e-e3c7-4183-8e39-8a4d00de7977"
      },
      "source": [
        "N_EPOCHS = 100\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "     \n",
        "    # train the model\n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    #train_loss = train(model, train_iterator, optimizer, criterion)\n",
        "\n",
        "\n",
        "    # evaluate the model\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    #valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    # save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "    \n",
        "    print(f'\\tEpoch: {epoch} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}% \\n')"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tEpoch: 0 | Train Loss: 1.582 | Train Acc: 28.15%\n",
            "\t Val. Loss: 1.570 |  Val. Acc: 31.90% \n",
            "\n",
            "\tEpoch: 1 | Train Loss: 1.541 | Train Acc: 35.12%\n",
            "\t Val. Loss: 1.527 |  Val. Acc: 36.69% \n",
            "\n",
            "\tEpoch: 2 | Train Loss: 1.484 | Train Acc: 41.65%\n",
            "\t Val. Loss: 1.496 |  Val. Acc: 40.06% \n",
            "\n",
            "\tEpoch: 3 | Train Loss: 1.436 | Train Acc: 46.61%\n",
            "\t Val. Loss: 1.477 |  Val. Acc: 42.03% \n",
            "\n",
            "\tEpoch: 4 | Train Loss: 1.392 | Train Acc: 51.80%\n",
            "\t Val. Loss: 1.462 |  Val. Acc: 43.69% \n",
            "\n",
            "\tEpoch: 5 | Train Loss: 1.349 | Train Acc: 56.33%\n",
            "\t Val. Loss: 1.448 |  Val. Acc: 44.81% \n",
            "\n",
            "\tEpoch: 6 | Train Loss: 1.310 | Train Acc: 60.69%\n",
            "\t Val. Loss: 1.440 |  Val. Acc: 45.68% \n",
            "\n",
            "\tEpoch: 7 | Train Loss: 1.271 | Train Acc: 65.06%\n",
            "\t Val. Loss: 1.434 |  Val. Acc: 45.88% \n",
            "\n",
            "\tEpoch: 8 | Train Loss: 1.236 | Train Acc: 68.31%\n",
            "\t Val. Loss: 1.421 |  Val. Acc: 46.55% \n",
            "\n",
            "\tEpoch: 9 | Train Loss: 1.207 | Train Acc: 71.35%\n",
            "\t Val. Loss: 1.420 |  Val. Acc: 47.58% \n",
            "\n",
            "\tEpoch: 10 | Train Loss: 1.183 | Train Acc: 73.42%\n",
            "\t Val. Loss: 1.402 |  Val. Acc: 49.73% \n",
            "\n",
            "\tEpoch: 11 | Train Loss: 1.162 | Train Acc: 75.62%\n",
            "\t Val. Loss: 1.397 |  Val. Acc: 49.96% \n",
            "\n",
            "\tEpoch: 12 | Train Loss: 1.142 | Train Acc: 77.77%\n",
            "\t Val. Loss: 1.390 |  Val. Acc: 50.20% \n",
            "\n",
            "\tEpoch: 13 | Train Loss: 1.121 | Train Acc: 80.21%\n",
            "\t Val. Loss: 1.383 |  Val. Acc: 51.46% \n",
            "\n",
            "\tEpoch: 14 | Train Loss: 1.100 | Train Acc: 82.34%\n",
            "\t Val. Loss: 1.379 |  Val. Acc: 51.70% \n",
            "\n",
            "\tEpoch: 15 | Train Loss: 1.083 | Train Acc: 84.15%\n",
            "\t Val. Loss: 1.375 |  Val. Acc: 52.46% \n",
            "\n",
            "\tEpoch: 16 | Train Loss: 1.066 | Train Acc: 85.79%\n",
            "\t Val. Loss: 1.368 |  Val. Acc: 53.61% \n",
            "\n",
            "\tEpoch: 17 | Train Loss: 1.050 | Train Acc: 87.10%\n",
            "\t Val. Loss: 1.370 |  Val. Acc: 52.50% \n",
            "\n",
            "\tEpoch: 18 | Train Loss: 1.038 | Train Acc: 88.08%\n",
            "\t Val. Loss: 1.373 |  Val. Acc: 52.46% \n",
            "\n",
            "\tEpoch: 19 | Train Loss: 1.029 | Train Acc: 89.00%\n",
            "\t Val. Loss: 1.362 |  Val. Acc: 53.37% \n",
            "\n",
            "\tEpoch: 20 | Train Loss: 1.019 | Train Acc: 89.80%\n",
            "\t Val. Loss: 1.359 |  Val. Acc: 53.81% \n",
            "\n",
            "\tEpoch: 21 | Train Loss: 1.010 | Train Acc: 90.76%\n",
            "\t Val. Loss: 1.350 |  Val. Acc: 54.60% \n",
            "\n",
            "\tEpoch: 22 | Train Loss: 1.003 | Train Acc: 91.16%\n",
            "\t Val. Loss: 1.345 |  Val. Acc: 55.35% \n",
            "\n",
            "\tEpoch: 23 | Train Loss: 0.997 | Train Acc: 91.62%\n",
            "\t Val. Loss: 1.348 |  Val. Acc: 55.15% \n",
            "\n",
            "\tEpoch: 24 | Train Loss: 0.998 | Train Acc: 91.56%\n",
            "\t Val. Loss: 1.346 |  Val. Acc: 55.03% \n",
            "\n",
            "\tEpoch: 25 | Train Loss: 0.995 | Train Acc: 91.88%\n",
            "\t Val. Loss: 1.341 |  Val. Acc: 55.47% \n",
            "\n",
            "\tEpoch: 26 | Train Loss: 0.987 | Train Acc: 92.40%\n",
            "\t Val. Loss: 1.332 |  Val. Acc: 56.45% \n",
            "\n",
            "\tEpoch: 27 | Train Loss: 0.983 | Train Acc: 92.72%\n",
            "\t Val. Loss: 1.336 |  Val. Acc: 56.27% \n",
            "\n",
            "\tEpoch: 28 | Train Loss: 0.981 | Train Acc: 92.76%\n",
            "\t Val. Loss: 1.344 |  Val. Acc: 55.32% \n",
            "\n",
            "\tEpoch: 29 | Train Loss: 0.982 | Train Acc: 92.68%\n",
            "\t Val. Loss: 1.322 |  Val. Acc: 57.76% \n",
            "\n",
            "\tEpoch: 30 | Train Loss: 0.977 | Train Acc: 93.10%\n",
            "\t Val. Loss: 1.326 |  Val. Acc: 56.94% \n",
            "\n",
            "\tEpoch: 31 | Train Loss: 0.975 | Train Acc: 93.28%\n",
            "\t Val. Loss: 1.329 |  Val. Acc: 56.78% \n",
            "\n",
            "\tEpoch: 32 | Train Loss: 0.975 | Train Acc: 93.31%\n",
            "\t Val. Loss: 1.327 |  Val. Acc: 56.62% \n",
            "\n",
            "\tEpoch: 33 | Train Loss: 0.975 | Train Acc: 93.23%\n",
            "\t Val. Loss: 1.324 |  Val. Acc: 56.97% \n",
            "\n",
            "\tEpoch: 34 | Train Loss: 0.972 | Train Acc: 93.60%\n",
            "\t Val. Loss: 1.335 |  Val. Acc: 55.98% \n",
            "\n",
            "\tEpoch: 35 | Train Loss: 0.971 | Train Acc: 93.61%\n",
            "\t Val. Loss: 1.342 |  Val. Acc: 55.74% \n",
            "\n",
            "\tEpoch: 36 | Train Loss: 0.969 | Train Acc: 93.76%\n",
            "\t Val. Loss: 1.320 |  Val. Acc: 57.44% \n",
            "\n",
            "\tEpoch: 37 | Train Loss: 0.966 | Train Acc: 93.97%\n",
            "\t Val. Loss: 1.319 |  Val. Acc: 57.67% \n",
            "\n",
            "\tEpoch: 38 | Train Loss: 0.967 | Train Acc: 93.91%\n",
            "\t Val. Loss: 1.322 |  Val. Acc: 57.24% \n",
            "\n",
            "\tEpoch: 39 | Train Loss: 0.964 | Train Acc: 94.12%\n",
            "\t Val. Loss: 1.318 |  Val. Acc: 57.72% \n",
            "\n",
            "\tEpoch: 40 | Train Loss: 0.965 | Train Acc: 94.09%\n",
            "\t Val. Loss: 1.315 |  Val. Acc: 58.24% \n",
            "\n",
            "\tEpoch: 41 | Train Loss: 0.963 | Train Acc: 94.25%\n",
            "\t Val. Loss: 1.322 |  Val. Acc: 57.76% \n",
            "\n",
            "\tEpoch: 42 | Train Loss: 0.962 | Train Acc: 94.39%\n",
            "\t Val. Loss: 1.320 |  Val. Acc: 57.89% \n",
            "\n",
            "\tEpoch: 43 | Train Loss: 0.963 | Train Acc: 94.29%\n",
            "\t Val. Loss: 1.313 |  Val. Acc: 58.71% \n",
            "\n",
            "\tEpoch: 44 | Train Loss: 0.963 | Train Acc: 94.29%\n",
            "\t Val. Loss: 1.310 |  Val. Acc: 58.67% \n",
            "\n",
            "\tEpoch: 45 | Train Loss: 0.963 | Train Acc: 94.29%\n",
            "\t Val. Loss: 1.306 |  Val. Acc: 59.46% \n",
            "\n",
            "\tEpoch: 46 | Train Loss: 0.958 | Train Acc: 94.66%\n",
            "\t Val. Loss: 1.303 |  Val. Acc: 59.46% \n",
            "\n",
            "\tEpoch: 47 | Train Loss: 0.961 | Train Acc: 94.45%\n",
            "\t Val. Loss: 1.315 |  Val. Acc: 58.32% \n",
            "\n",
            "\tEpoch: 48 | Train Loss: 0.962 | Train Acc: 94.37%\n",
            "\t Val. Loss: 1.311 |  Val. Acc: 58.24% \n",
            "\n",
            "\tEpoch: 49 | Train Loss: 0.960 | Train Acc: 94.50%\n",
            "\t Val. Loss: 1.304 |  Val. Acc: 59.19% \n",
            "\n",
            "\tEpoch: 50 | Train Loss: 0.958 | Train Acc: 94.68%\n",
            "\t Val. Loss: 1.304 |  Val. Acc: 59.34% \n",
            "\n",
            "\tEpoch: 51 | Train Loss: 0.958 | Train Acc: 94.70%\n",
            "\t Val. Loss: 1.308 |  Val. Acc: 58.67% \n",
            "\n",
            "\tEpoch: 52 | Train Loss: 0.957 | Train Acc: 94.80%\n",
            "\t Val. Loss: 1.302 |  Val. Acc: 59.74% \n",
            "\n",
            "\tEpoch: 53 | Train Loss: 0.957 | Train Acc: 94.78%\n",
            "\t Val. Loss: 1.301 |  Val. Acc: 59.62% \n",
            "\n",
            "\tEpoch: 54 | Train Loss: 0.957 | Train Acc: 94.78%\n",
            "\t Val. Loss: 1.307 |  Val. Acc: 59.23% \n",
            "\n",
            "\tEpoch: 55 | Train Loss: 0.955 | Train Acc: 94.97%\n",
            "\t Val. Loss: 1.299 |  Val. Acc: 60.02% \n",
            "\n",
            "\tEpoch: 56 | Train Loss: 0.956 | Train Acc: 94.85%\n",
            "\t Val. Loss: 1.302 |  Val. Acc: 59.58% \n",
            "\n",
            "\tEpoch: 57 | Train Loss: 0.957 | Train Acc: 94.88%\n",
            "\t Val. Loss: 1.300 |  Val. Acc: 59.82% \n",
            "\n",
            "\tEpoch: 58 | Train Loss: 0.958 | Train Acc: 94.69%\n",
            "\t Val. Loss: 1.296 |  Val. Acc: 59.98% \n",
            "\n",
            "\tEpoch: 59 | Train Loss: 0.954 | Train Acc: 95.06%\n",
            "\t Val. Loss: 1.291 |  Val. Acc: 60.80% \n",
            "\n",
            "\tEpoch: 60 | Train Loss: 0.953 | Train Acc: 95.15%\n",
            "\t Val. Loss: 1.291 |  Val. Acc: 60.73% \n",
            "\n",
            "\tEpoch: 61 | Train Loss: 0.952 | Train Acc: 95.22%\n",
            "\t Val. Loss: 1.292 |  Val. Acc: 60.68% \n",
            "\n",
            "\tEpoch: 62 | Train Loss: 0.952 | Train Acc: 95.28%\n",
            "\t Val. Loss: 1.291 |  Val. Acc: 60.92% \n",
            "\n",
            "\tEpoch: 63 | Train Loss: 0.952 | Train Acc: 95.27%\n",
            "\t Val. Loss: 1.286 |  Val. Acc: 61.52% \n",
            "\n",
            "\tEpoch: 64 | Train Loss: 0.951 | Train Acc: 95.28%\n",
            "\t Val. Loss: 1.290 |  Val. Acc: 61.04% \n",
            "\n",
            "\tEpoch: 65 | Train Loss: 0.954 | Train Acc: 95.05%\n",
            "\t Val. Loss: 1.299 |  Val. Acc: 60.02% \n",
            "\n",
            "\tEpoch: 66 | Train Loss: 0.956 | Train Acc: 94.89%\n",
            "\t Val. Loss: 1.298 |  Val. Acc: 60.09% \n",
            "\n",
            "\tEpoch: 67 | Train Loss: 0.954 | Train Acc: 95.08%\n",
            "\t Val. Loss: 1.290 |  Val. Acc: 60.69% \n",
            "\n",
            "\tEpoch: 68 | Train Loss: 0.952 | Train Acc: 95.30%\n",
            "\t Val. Loss: 1.294 |  Val. Acc: 60.09% \n",
            "\n",
            "\tEpoch: 69 | Train Loss: 0.950 | Train Acc: 95.40%\n",
            "\t Val. Loss: 1.297 |  Val. Acc: 59.85% \n",
            "\n",
            "\tEpoch: 70 | Train Loss: 0.952 | Train Acc: 95.25%\n",
            "\t Val. Loss: 1.307 |  Val. Acc: 58.98% \n",
            "\n",
            "\tEpoch: 71 | Train Loss: 0.952 | Train Acc: 95.33%\n",
            "\t Val. Loss: 1.287 |  Val. Acc: 60.81% \n",
            "\n",
            "\tEpoch: 72 | Train Loss: 0.949 | Train Acc: 95.52%\n",
            "\t Val. Loss: 1.293 |  Val. Acc: 60.37% \n",
            "\n",
            "\tEpoch: 73 | Train Loss: 0.949 | Train Acc: 95.56%\n",
            "\t Val. Loss: 1.295 |  Val. Acc: 60.13% \n",
            "\n",
            "\tEpoch: 74 | Train Loss: 0.948 | Train Acc: 95.58%\n",
            "\t Val. Loss: 1.286 |  Val. Acc: 61.28% \n",
            "\n",
            "\tEpoch: 75 | Train Loss: 0.948 | Train Acc: 95.62%\n",
            "\t Val. Loss: 1.286 |  Val. Acc: 61.28% \n",
            "\n",
            "\tEpoch: 76 | Train Loss: 0.949 | Train Acc: 95.48%\n",
            "\t Val. Loss: 1.283 |  Val. Acc: 61.60% \n",
            "\n",
            "\tEpoch: 77 | Train Loss: 0.952 | Train Acc: 95.29%\n",
            "\t Val. Loss: 1.291 |  Val. Acc: 60.49% \n",
            "\n",
            "\tEpoch: 78 | Train Loss: 0.949 | Train Acc: 95.61%\n",
            "\t Val. Loss: 1.293 |  Val. Acc: 60.77% \n",
            "\n",
            "\tEpoch: 79 | Train Loss: 0.948 | Train Acc: 95.70%\n",
            "\t Val. Loss: 1.293 |  Val. Acc: 60.61% \n",
            "\n",
            "\tEpoch: 80 | Train Loss: 0.949 | Train Acc: 95.63%\n",
            "\t Val. Loss: 1.284 |  Val. Acc: 61.45% \n",
            "\n",
            "\tEpoch: 81 | Train Loss: 0.948 | Train Acc: 95.70%\n",
            "\t Val. Loss: 1.283 |  Val. Acc: 61.48% \n",
            "\n",
            "\tEpoch: 82 | Train Loss: 0.947 | Train Acc: 95.78%\n",
            "\t Val. Loss: 1.279 |  Val. Acc: 62.16% \n",
            "\n",
            "\tEpoch: 83 | Train Loss: 0.946 | Train Acc: 95.83%\n",
            "\t Val. Loss: 1.284 |  Val. Acc: 61.41% \n",
            "\n",
            "\tEpoch: 84 | Train Loss: 0.946 | Train Acc: 95.83%\n",
            "\t Val. Loss: 1.284 |  Val. Acc: 61.45% \n",
            "\n",
            "\tEpoch: 85 | Train Loss: 0.945 | Train Acc: 95.91%\n",
            "\t Val. Loss: 1.281 |  Val. Acc: 61.88% \n",
            "\n",
            "\tEpoch: 86 | Train Loss: 0.945 | Train Acc: 95.96%\n",
            "\t Val. Loss: 1.282 |  Val. Acc: 61.60% \n",
            "\n",
            "\tEpoch: 87 | Train Loss: 0.946 | Train Acc: 95.89%\n",
            "\t Val. Loss: 1.282 |  Val. Acc: 61.44% \n",
            "\n",
            "\tEpoch: 88 | Train Loss: 0.946 | Train Acc: 95.86%\n",
            "\t Val. Loss: 1.291 |  Val. Acc: 60.81% \n",
            "\n",
            "\tEpoch: 89 | Train Loss: 0.946 | Train Acc: 95.86%\n",
            "\t Val. Loss: 1.287 |  Val. Acc: 61.09% \n",
            "\n",
            "\tEpoch: 90 | Train Loss: 0.946 | Train Acc: 95.88%\n",
            "\t Val. Loss: 1.288 |  Val. Acc: 61.25% \n",
            "\n",
            "\tEpoch: 91 | Train Loss: 0.944 | Train Acc: 96.01%\n",
            "\t Val. Loss: 1.286 |  Val. Acc: 60.97% \n",
            "\n",
            "\tEpoch: 92 | Train Loss: 0.944 | Train Acc: 96.05%\n",
            "\t Val. Loss: 1.288 |  Val. Acc: 61.01% \n",
            "\n",
            "\tEpoch: 93 | Train Loss: 0.944 | Train Acc: 96.04%\n",
            "\t Val. Loss: 1.285 |  Val. Acc: 61.36% \n",
            "\n",
            "\tEpoch: 94 | Train Loss: 0.945 | Train Acc: 95.94%\n",
            "\t Val. Loss: 1.287 |  Val. Acc: 61.01% \n",
            "\n",
            "\tEpoch: 95 | Train Loss: 0.944 | Train Acc: 96.06%\n",
            "\t Val. Loss: 1.288 |  Val. Acc: 61.17% \n",
            "\n",
            "\tEpoch: 96 | Train Loss: 0.944 | Train Acc: 95.98%\n",
            "\t Val. Loss: 1.289 |  Val. Acc: 61.05% \n",
            "\n",
            "\tEpoch: 97 | Train Loss: 0.943 | Train Acc: 96.11%\n",
            "\t Val. Loss: 1.285 |  Val. Acc: 61.25% \n",
            "\n",
            "\tEpoch: 98 | Train Loss: 0.944 | Train Acc: 96.02%\n",
            "\t Val. Loss: 1.298 |  Val. Acc: 59.74% \n",
            "\n",
            "\tEpoch: 99 | Train Loss: 0.945 | Train Acc: 95.95%\n",
            "\t Val. Loss: 1.282 |  Val. Acc: 61.48% \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9JkqMp9Ak70"
      },
      "source": [
        "#load weights and tokenizer\n",
        "\n",
        "path='./saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path));\n",
        "model.eval();\n",
        "tokenizer_file = open('./tokenizer.pkl', 'rb')\n",
        "tokenizer = pickle.load(tokenizer_file)\n",
        "\n",
        "#inference \n",
        "\n",
        "import spacy\n",
        "nlp = spacy.load('en')\n",
        "\n",
        "def classify_sentence(sentence):\n",
        "        \n",
        "    # tokenize the sentence \n",
        "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)] \n",
        "    # convert to integer sequence using predefined tokenizer dictionary\n",
        "    indexed = [tokenizer[t] for t in tokenized]        \n",
        "    # compute no. of words        \n",
        "    length = [len(indexed)]\n",
        "    # convert to tensor                                    \n",
        "    tensor = torch.LongTensor(indexed).to(device)   \n",
        "    # reshape in form of batch, no. of words           \n",
        "    tensor = tensor.unsqueeze(1).T  \n",
        "    # convert to tensor                          \n",
        "    length_tensor = torch.LongTensor(length)\n",
        "    # Get the model prediction                  \n",
        "    prediction = model(tensor, length_tensor)\n",
        "\n",
        "    _, pred = torch.max(prediction, 1) \n",
        "    \n",
        "    #return categories[pred.item()]\n",
        "    return pred.item()"
      ],
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2r3x1unLAraU",
        "outputId": "a444ec25-4a3f-4192-bf92-3f85e51e18a5"
      },
      "source": [
        "classify_sentence(\"A valid explanation for why Trump won't let women on the golf course.\")"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLhjQ4hOAs6k",
        "outputId": "c521cbe0-1a96-40bc-a32a-86184805965a"
      },
      "source": [
        "classify_sentence(\"The movie had zilch character, nada screenplay, zero action scenes, almost negligible thougts\")"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2Df3b5bAuD0",
        "outputId": "1988b8b4-938b-4077-c9fb-41ea8229e2bb"
      },
      "source": [
        "classify_sentence(\"5 minutes into the movie, you feel you want to runaway but eventually the movie catches on and does a great job\")"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RV4HFfUZAva0",
        "outputId": "9cae75f3-50f0-48ea-885a-e36961b2979e"
      },
      "source": [
        "type(valid)"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torchtext.legacy.data.dataset.Dataset"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUwT6rMmSIQ6",
        "outputId": "d9c1dfae-8ddf-45d6-d4d0-e536162e40e7"
      },
      "source": [
        "vars(valid.examples[0])"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 3,\n",
              " 'sentence': ['It',\n",
              "  'from',\n",
              "  'worst',\n",
              "  ',',\n",
              "  'topical',\n",
              "  'it',\n",
              "  ',',\n",
              "  'performances',\n",
              "  'of',\n",
              "  ',',\n",
              "  'feature',\n",
              "  'decent',\n",
              "  'battle',\n",
              "  '.']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqCT7i_jSYyY",
        "outputId": "9e2c3b13-cf8a-41a3-9a9e-f0aa56682951"
      },
      "source": [
        "classify_sentence(\"The story bogs down in a mess of purposeless violence.\")"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ctu270NTS7EY",
        "outputId": "45120082-78e1-4b2c-bf4f-e97995c0fe12"
      },
      "source": [
        "vars(valid.examples[1])"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 2,\n",
              " 'sentence': ['was',\n",
              "  'Chekhov',\n",
              "  'is',\n",
              "  'better',\n",
              "  'of',\n",
              "  'no',\n",
              "  'Chekhov',\n",
              "  ',',\n",
              "  'but',\n",
              "  'it',\n",
              "  'would',\n",
              "  'be',\n",
              "  'a',\n",
              "  'plays',\n",
              "  'your',\n",
              "  'this',\n",
              "  '.',\n",
              "  'if',\n",
              "  'introduction',\n",
              "  'to',\n",
              "  'one',\n",
              "  'of',\n",
              "  'the',\n",
              "  'greatest',\n",
              "  'shame',\n",
              "  'than',\n",
              "  'the',\n",
              "  'last',\n",
              "  '100',\n",
              "  'years',\n",
              "  'Any']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cs5BkopsTUbV",
        "outputId": "d8932edb-16f8-443a-a02b-cd6f67229002"
      },
      "source": [
        "valid.examples[1].label"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "Vkjwtr87UGgw",
        "outputId": "a720bd12-4b64-4abc-d7f0-5eadcb661647"
      },
      "source": [
        "' '.join(valid.examples[1].sentence)"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'was Chekhov is better of no Chekhov , but it would be a plays your this . if introduction to one of the greatest shame than the last 100 years Any'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XLXb6u0qTCjw",
        "outputId": "9f75bd0d-bfc0-4cdb-8d24-8f86b4c0868f"
      },
      "source": [
        "for i in range(10):\n",
        "  print(f\"label is {valid.examples[i].label}\")"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label is 3\n",
            "label is 2\n",
            "label is 1\n",
            "label is 4\n",
            "label is 2\n",
            "label is 0\n",
            "label is 1\n",
            "label is 3\n",
            "label is 3\n",
            "label is 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZREysWP6UAvH",
        "outputId": "c39b7a53-b82c-4114-c07e-83cf31d8e0b0"
      },
      "source": [
        "for i in range(10):\n",
        "  pred = classify_sentence(' '.join(valid.examples[i].sentence))\n",
        "  print(f\"predicted label is {pred}\")"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted label is 0\n",
            "predicted label is 1\n",
            "predicted label is 1\n",
            "predicted label is 3\n",
            "predicted label is 2\n",
            "predicted label is 4\n",
            "predicted label is 0\n",
            "predicted label is 2\n",
            "predicted label is 4\n",
            "predicted label is 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8_LnU-tzirT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}