{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Session 5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO97fK7wf84Lyd9LCgWBb7W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SomaKorada07/END2.0/blob/main/Session%205/Session_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwA6ZAP0gV57"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "ggimqGoi_BqW",
        "outputId": "ceb8e236-482e-455d-aef9-daf0a23ab7ad"
      },
      "source": [
        "df = pd.read_csv('/content/datasetSentences.txt', sep = '\\t', header = 0)\n",
        "df.head()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_index</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Effective but too-tepid biopic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>If you sometimes like to go to the movies to h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Emerges as something rare , an issue movie tha...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentence_index                                           sentence\n",
              "0               1  The Rock is destined to be the 21st Century 's...\n",
              "1               2  The gorgeously elaborate continuation of `` Th...\n",
              "2               3                     Effective but too-tepid biopic\n",
              "3               4  If you sometimes like to go to the movies to h...\n",
              "4               5  Emerges as something rare , an issue movie tha..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiurY2gQK7iI",
        "outputId": "b956e522-c9b3-4a6c-e633-7fe275218f85"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['sentence_index', 'sentence'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DelWJDZTRyA",
        "outputId": "efd6e70d-46b9-4d82-8313-aba3127486de"
      },
      "source": [
        "len(df['sentence_index']), len(df['sentence'])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11855, 11855)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "iIJeCQHsTZhQ",
        "outputId": "1e04decb-cd12-4e87-c809-fddaae9f8098"
      },
      "source": [
        "df_labels = pd.read_csv('/content/sentiment_labels.txt', sep = '|', header = 0)\n",
        "df_labels.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>phrase ids</th>\n",
              "      <th>sentiment values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.50000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.50000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.44444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.50000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.42708</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   phrase ids  sentiment values\n",
              "0           0           0.50000\n",
              "1           1           0.50000\n",
              "2           2           0.44444\n",
              "3           3           0.50000\n",
              "4           4           0.42708"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eB9MaMYURug",
        "outputId": "56136c98-780d-456e-8678-79aae8617972"
      },
      "source": [
        "len(df_labels)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "239232"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "YBZMpE52U4bO",
        "outputId": "b4e24363-eb1c-43ef-cc2b-5c5e841c4699"
      },
      "source": [
        "df_dict = pd.read_csv('/content/dictionary.txt', sep = '|', header = None)\n",
        "df_dict.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>!</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>! '</td>\n",
              "      <td>22935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>! ''</td>\n",
              "      <td>18235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>! Alas</td>\n",
              "      <td>179257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>! Brilliant</td>\n",
              "      <td>22936</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             0       1\n",
              "0            !       0\n",
              "1          ! '   22935\n",
              "2         ! ''   18235\n",
              "3       ! Alas  179257\n",
              "4  ! Brilliant   22936"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTAZoTo2VtPh",
        "outputId": "16d42f03-48ce-4c43-ab3f-e9099a7db117"
      },
      "source": [
        "df_dict.columns"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Int64Index([0, 1], dtype='int64')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDRsZFU793iO",
        "outputId": "b4414585-b7b2-4df0-e23e-720b1e40b726"
      },
      "source": [
        "type(df_dict[0]), type(df_dict[1])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(pandas.core.series.Series, pandas.core.series.Series)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5iFm-oU_NVc"
      },
      "source": [
        "df_dict.rename(columns = {0: 'phrase', 1: 'phrase ids'}, inplace = True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1HKRPz1-a5P"
      },
      "source": [
        "# pd.to_numeric(df_dict[1], downcast='integer')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "hjG4vzWE-2eu",
        "outputId": "41f58d21-25c2-46ef-f7b6-e929b6cc77b4"
      },
      "source": [
        "df_dict.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>phrase</th>\n",
              "      <th>phrase ids</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>!</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>! '</td>\n",
              "      <td>22935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>! ''</td>\n",
              "      <td>18235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>! Alas</td>\n",
              "      <td>179257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>! Brilliant</td>\n",
              "      <td>22936</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        phrase  phrase ids\n",
              "0            !           0\n",
              "1          ! '       22935\n",
              "2         ! ''       18235\n",
              "3       ! Alas      179257\n",
              "4  ! Brilliant       22936"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2YC5_s2-4se"
      },
      "source": [
        "df_target = pd.merge(df_labels, df_dict, how = 'inner', left_on = 'phrase ids', right_on = 'phrase ids')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "MQcvoLqRAR9x",
        "outputId": "002fa957-227b-4e44-a591-514b0025f358"
      },
      "source": [
        "df_target.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>phrase ids</th>\n",
              "      <th>sentiment values</th>\n",
              "      <th>phrase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.50000</td>\n",
              "      <td>!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.50000</td>\n",
              "      <td>'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.44444</td>\n",
              "      <td>' (</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.50000</td>\n",
              "      <td>' ( the cockettes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.42708</td>\n",
              "      <td>' ( the cockettes )</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   phrase ids  sentiment values               phrase\n",
              "0           0           0.50000                    !\n",
              "1           1           0.50000                    '\n",
              "2           2           0.44444                  ' (\n",
              "3           3           0.50000    ' ( the cockettes\n",
              "4           4           0.42708  ' ( the cockettes )"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIK9S5H7AY8c"
      },
      "source": [
        "common_sentences = df[df['sentence'].isin(df_target['phrase'])]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "5mMH9uladVEQ",
        "outputId": "b16f5690-8c1b-43bd-c5a9-c9567158b4c3"
      },
      "source": [
        "common_sentences"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_index</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Effective but too-tepid biopic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>If you sometimes like to go to the movies to h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Emerges as something rare , an issue movie tha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11850</th>\n",
              "      <td>11851</td>\n",
              "      <td>A real snooze .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11851</th>\n",
              "      <td>11852</td>\n",
              "      <td>No surprises .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11852</th>\n",
              "      <td>11853</td>\n",
              "      <td>We 've seen the hippie-turned-yuppie plot befo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11853</th>\n",
              "      <td>11854</td>\n",
              "      <td>Her fans walked out muttering words like `` ho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11854</th>\n",
              "      <td>11855</td>\n",
              "      <td>In this case zero .</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11286 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       sentence_index                                           sentence\n",
              "0                   1  The Rock is destined to be the 21st Century 's...\n",
              "1                   2  The gorgeously elaborate continuation of `` Th...\n",
              "2                   3                     Effective but too-tepid biopic\n",
              "3                   4  If you sometimes like to go to the movies to h...\n",
              "4                   5  Emerges as something rare , an issue movie tha...\n",
              "...               ...                                                ...\n",
              "11850           11851                                    A real snooze .\n",
              "11851           11852                                     No surprises .\n",
              "11852           11853  We 've seen the hippie-turned-yuppie plot befo...\n",
              "11853           11854  Her fans walked out muttering words like `` ho...\n",
              "11854           11855                                In this case zero .\n",
              "\n",
              "[11286 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URUeg8VRe-l_"
      },
      "source": [
        "def sentence_exists(input_sentence):\n",
        "    matching_phrase = df_target[df_target[\"phrase\"] == input_sentence][\"phrase ids\"].values\n",
        "    default_series = pd.Series({\"phrase ids\":-1000, \"sentiment values\": -1000}) ## For cases where we dont find a full sentence match\n",
        "    if(len(matching_phrase)) > 0:\n",
        "        phrase_id = np.int(matching_phrase[0])\n",
        "        sentiment_value = df_target[df_target[\"phrase ids\"] == matching_phrase[0]][\"sentiment values\"].values[0]\n",
        "        default_series = pd.Series({\"phrase ids\":phrase_id, \"sentiment values\": sentiment_value})\n",
        "\n",
        "    return default_series"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoLGHT5sdWet"
      },
      "source": [
        "common_sentences.loc[:, [\"phrase ids\", \"sentiment values\"]] =  common_sentences.loc[:,\"sentence\"].apply(sentence_exists)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "reRBbzyjghjN",
        "outputId": "ffe63130-1741-4299-ddf5-1c16e90069ee"
      },
      "source": [
        "common_sentences.head()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_index</th>\n",
              "      <th>sentence</th>\n",
              "      <th>phrase ids</th>\n",
              "      <th>sentiment values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
              "      <td>226166.0</td>\n",
              "      <td>0.69444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
              "      <td>226300.0</td>\n",
              "      <td>0.83333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Effective but too-tepid biopic</td>\n",
              "      <td>13995.0</td>\n",
              "      <td>0.51389</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>If you sometimes like to go to the movies to h...</td>\n",
              "      <td>14123.0</td>\n",
              "      <td>0.73611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Emerges as something rare , an issue movie tha...</td>\n",
              "      <td>13999.0</td>\n",
              "      <td>0.86111</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentence_index  ... sentiment values\n",
              "0               1  ...          0.69444\n",
              "1               2  ...          0.83333\n",
              "2               3  ...          0.51389\n",
              "3               4  ...          0.73611\n",
              "4               5  ...          0.86111\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAxDwEL7gAws",
        "outputId": "51185c56-124f-4cf6-833f-798d5eaafe71"
      },
      "source": [
        "pd.to_numeric(common_sentences['phrase ids'], downcast='integer')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        226166\n",
              "1        226300\n",
              "2         13995\n",
              "3         14123\n",
              "4         13999\n",
              "          ...  \n",
              "11850    222071\n",
              "11851    225165\n",
              "11852    226985\n",
              "11853    223632\n",
              "11854    224044\n",
              "Name: phrase ids, Length: 11286, dtype: int32"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "2i9MdAXxhisV",
        "outputId": "5bb5a6af-45e5-410d-dcf9-4d12cceef69a"
      },
      "source": [
        "common_sentences.head()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_index</th>\n",
              "      <th>sentence</th>\n",
              "      <th>phrase ids</th>\n",
              "      <th>sentiment values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
              "      <td>226166.0</td>\n",
              "      <td>0.69444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
              "      <td>226300.0</td>\n",
              "      <td>0.83333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Effective but too-tepid biopic</td>\n",
              "      <td>13995.0</td>\n",
              "      <td>0.51389</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>If you sometimes like to go to the movies to h...</td>\n",
              "      <td>14123.0</td>\n",
              "      <td>0.73611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Emerges as something rare , an issue movie tha...</td>\n",
              "      <td>13999.0</td>\n",
              "      <td>0.86111</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentence_index  ... sentiment values\n",
              "0               1  ...          0.69444\n",
              "1               2  ...          0.83333\n",
              "2               3  ...          0.51389\n",
              "3               4  ...          0.73611\n",
              "4               5  ...          0.86111\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ny757bpjhkN6",
        "outputId": "0ebc5f4e-3eaf-41ad-e6c1-5aefc3a6dd88"
      },
      "source": [
        "common_sentences.shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11286, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8ddu7a2lgCk"
      },
      "source": [
        "# Training and test dataset\n",
        "After applying above techiniques we get a combined DataFrame that has the following fields:\n",
        "\n",
        "*   sentence_index : Original sentence_index in the datasetSentences.txt\n",
        "*   sentence: The actual sentence\n",
        "*   Phrase_Id: The Phrase_Id used for mapping/retrieving sentiment score\n",
        "*   Sentiment_Score: Actual Sentiment score for the sentence\n",
        "\n",
        "Now we split the DataFrame into Training and Test Dataframes. Note that we are not using the recommended train/ dev /test splits from the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKMNKE38hwHa"
      },
      "source": [
        "train_df = common_sentences.sample(frac = 0.8) \n",
        "test_df = common_sentences[~common_sentences.sentence_index.isin(train_df.sentence_index)]"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oQLB7lymZxj",
        "outputId": "90760118-ba48-4713-c531-1a216bb6a629"
      },
      "source": [
        "train_df.shape, test_df.shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((9029, 4), (2257, 4))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQBYauo7meTH"
      },
      "source": [
        "train_df.to_csv(\"StanfordTrain.csv\", index=False, sep=\"|\")\n",
        "test_df.to_csv(\"StanfordTest.csv\", index=False, sep=\"|\")"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7uGPt4YqJno"
      },
      "source": [
        "# Data Augmentation Techniques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSupdZC0qM9P"
      },
      "source": [
        "## **Random Swap**\n",
        "The random swap augmentation takes a sentence and then swaps words within it n times, with each iteration working on the previously swapped sentence. Here we sample two random numbers based on the length of the sentence, and then just keep swapping until we hit n."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqJzD5b3mvHn"
      },
      "source": [
        "def random_swap(sentence, n=5): \n",
        "    length = range(len(sentence)) \n",
        "    for _ in range(n):\n",
        "        idx1, idx2 = random.sample(length, 2)\n",
        "        sentence[idx1], sentence[idx2] = sentence[idx2], sentence[idx1] \n",
        "    return sentence"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pao1Y2GzqazO"
      },
      "source": [
        "For more on this please go through this [paper](https://arxiv.org/pdf/1901.11196.pdf)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvTxBI8Pqfhe"
      },
      "source": [
        "##**Back Translation**\n",
        "\n",
        "Another popular approach for augmenting text datasets is back translation. This involves translating a sentence from our target language into one or more other languages and then translating all of them back to the original language. We can use the Python library googletrans for this purpose. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVQTw0IIqzRQ",
        "outputId": "b3ecd43a-3b58-4109-8af8-f1c6cc06329e"
      },
      "source": [
        "!pip install googletrans==3.1.0a0"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting googletrans==3.1.0a0\n",
            "  Downloading https://files.pythonhosted.org/packages/19/3d/4e3a1609bf52f2f7b00436cc751eb977e27040665dde2bd57e7152989672/googletrans-3.1.0a0.tar.gz\n",
            "Collecting httpx==0.13.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/b4/698b284c6aed4d7c2b4fe3ba5df1fcf6093612423797e76fbb24890dd22f/httpx-0.13.3-py3-none-any.whl (55kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 1.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2020.12.5)\n",
            "Collecting hstspreload\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/50/606213e12fb49c5eb667df0936223dcaf461f94e215ea60244b2b1e9b039/hstspreload-2020.12.22-py3-none-any.whl (994kB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 3.4MB/s \n",
            "\u001b[?25hCollecting rfc3986<2,>=1.3\n",
            "  Downloading https://files.pythonhosted.org/packages/c4/e5/63ca2c4edf4e00657584608bee1001302bbf8c5f569340b78304f2f446cb/rfc3986-1.5.0-py2.py3-none-any.whl\n",
            "Collecting httpcore==0.9.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/d5/e4ff9318693ac6101a2095e580908b591838c6f33df8d3ee8dd953ba96a8/httpcore-0.9.1-py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 4.3MB/s \n",
            "\u001b[?25hCollecting sniffio\n",
            "  Downloading https://files.pythonhosted.org/packages/52/b0/7b2e028b63d092804b6794595871f936aafa5e9322dcaaad50ebf67445b3/sniffio-1.2.0-py3-none-any.whl\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2.10)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (3.0.4)\n",
            "Collecting h11<0.10,>=0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/fd/3dad730b0f95e78aeeb742f96fa7bbecbdd56a58e405d3da440d5bfb90c6/h11-0.9.0-py2.py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 4.4MB/s \n",
            "\u001b[?25hCollecting h2==3.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/de/da019bcc539eeab02f6d45836f23858ac467f584bfec7a526ef200242afe/h2-3.2.0-py2.py3-none-any.whl (65kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 4.1MB/s \n",
            "\u001b[?25hCollecting hpack<4,>=3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/8a/cc/e53517f4a1e13f74776ca93271caef378dadec14d71c61c949d759d3db69/hpack-3.0.0-py2.py3-none-any.whl\n",
            "Collecting hyperframe<6,>=5.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/19/0c/bf88182bcb5dce3094e2f3e4fe20db28a9928cb7bd5b08024030e4b140db/hyperframe-5.2.0-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: googletrans\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-3.1.0a0-cp37-none-any.whl size=16368 sha256=1fa0dfa5c94fe69534d1353300028114e73d3c599556bc7a944ab26532603b35\n",
            "  Stored in directory: /root/.cache/pip/wheels/27/7a/a0/aff3babbb775549ce6813cb8fa7ff3c0848c4dc62c20f8fdac\n",
            "Successfully built googletrans\n",
            "Installing collected packages: hstspreload, rfc3986, sniffio, h11, hpack, hyperframe, h2, httpcore, httpx, googletrans\n",
            "Successfully installed googletrans-3.1.0a0 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2020.12.22 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 rfc3986-1.5.0 sniffio-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "HV1Hy9zuqocA",
        "outputId": "d0489a5c-8cd3-4001-95ab-458ee9df52e0"
      },
      "source": [
        "import random\n",
        "import googletrans\n",
        "#import googletrans.Translator as Translator\n",
        "\n",
        "translator = googletrans.Translator()\n",
        "sentence = ['The dog slept on the rug', 'ran lazily']\n",
        "\n",
        "available_langs = list(googletrans.LANGUAGES.keys()) \n",
        "trans_lang = random.choice(available_langs) \n",
        "print(f\"Translating to {googletrans.LANGUAGES[trans_lang]}\")\n",
        "\n",
        "trans_lang"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Translating to urdu\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ur'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sXuwBrqqo3E",
        "outputId": "e4cc8cb0-513a-421c-c54b-7100c91329c0"
      },
      "source": [
        "sentence = ['The dog slept on the rug']\n",
        "available_langs = list(googletrans.LANGUAGES.keys()) \n",
        "trans_lang = random.choice(available_langs) \n",
        "print(f\"Translating to {googletrans.LANGUAGES[trans_lang]}\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Translating to swedish\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHWkiRkQrIne",
        "outputId": "1d08b235-4704-4629-ebe5-48bd89746342"
      },
      "source": [
        "translations = translator.translate(sentence, dest=trans_lang) \n",
        "t_text = [t.text for t in translations]\n",
        "print(t_text)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Hunden sov på mattan']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjXm8dedrKIk",
        "outputId": "70ea9d6d-d847-4a77-ed91-44f52abe566b"
      },
      "source": [
        "translations_en_random = translator.translate(t_text, src=trans_lang, dest='en') \n",
        "en_text = [t.text for t in translations_en_random]\n",
        "print(en_text)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['The dog slept on the carpet']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmEFdQjVrN2T"
      },
      "source": [
        "translator = googletrans.Translator()\n",
        "\n",
        "def back_translate(sentence):\n",
        "    available_langs = list(googletrans.LANGUAGES.keys()) \n",
        "    trans_lang = random.choice(available_langs) \n",
        "    translations = translator.translate(sentence, dest=trans_lang) \n",
        "    t_text = [t.text for t in translations]\n",
        "    translations_en_random = translator.translate(t_text, src=trans_lang, dest='en') \n",
        "    en_text = [t.text for t in translations_en_random]\n",
        "    return en_text"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqVUb6o_rU0z",
        "outputId": "bbc8dcbf-c5ae-4481-df2b-916295699fd5"
      },
      "source": [
        "back_translate([common_sentences.iloc[0].sentence])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"The Rock is destined to be the 21st Century 's new `` Conan '' and that he 's going to make a splash even greater than Arnold Schwarzenegger , Jean-Claud Van Damme or Steven Segal .\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdZV_kkSrnRD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6e15BFUr8RV"
      },
      "source": [
        "\n",
        "## **Data Augmentation**\n",
        "We use the EDA techniques referred in this [code](https://github.com/jasonwei20/eda_nlp). Our parameters for augmentation are as follows:\n",
        "\n",
        "*   Num_aug = 5 i.e 5 augmented sentences\n",
        "*   alpha_rs=0.2 i.e 20% percent of words in each sentence to be swapped\n",
        "*   alpha_rd=0.2 i.e 20% percent of words in each sentence to be dropped\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKnX76gXvW0j"
      },
      "source": [
        "import random\n",
        "from random import shuffle\n",
        "random.seed(1)\n",
        "\n",
        "#stop words list\n",
        "stop_words = ['i', 'me', 'my', 'myself', 'we', 'our', \n",
        "\t\t\t'ours', 'ourselves', 'you', 'your', 'yours', \n",
        "\t\t\t'yourself', 'yourselves', 'he', 'him', 'his', \n",
        "\t\t\t'himself', 'she', 'her', 'hers', 'herself', \n",
        "\t\t\t'it', 'its', 'itself', 'they', 'them', 'their', \n",
        "\t\t\t'theirs', 'themselves', 'what', 'which', 'who', \n",
        "\t\t\t'whom', 'this', 'that', 'these', 'those', 'am', \n",
        "\t\t\t'is', 'are', 'was', 'were', 'be', 'been', 'being', \n",
        "\t\t\t'have', 'has', 'had', 'having', 'do', 'does', 'did',\n",
        "\t\t\t'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or',\n",
        "\t\t\t'because', 'as', 'until', 'while', 'of', 'at', \n",
        "\t\t\t'by', 'for', 'with', 'about', 'against', 'between',\n",
        "\t\t\t'into', 'through', 'during', 'before', 'after', \n",
        "\t\t\t'above', 'below', 'to', 'from', 'up', 'down', 'in',\n",
        "\t\t\t'out', 'on', 'off', 'over', 'under', 'again', \n",
        "\t\t\t'further', 'then', 'once', 'here', 'there', 'when', \n",
        "\t\t\t'where', 'why', 'how', 'all', 'any', 'both', 'each', \n",
        "\t\t\t'few', 'more', 'most', 'other', 'some', 'such', 'no', \n",
        "\t\t\t'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', \n",
        "\t\t\t'very', 's', 't', 'can', 'will', 'just', 'don', \n",
        "\t\t\t'should', 'now', '']\n",
        "\n",
        "#cleaning up text\n",
        "import re\n",
        "def get_only_chars(line):\n",
        "\n",
        "    clean_line = \"\"\n",
        "\n",
        "    line = line.replace(\"’\", \"\")\n",
        "    line = line.replace(\"'\", \"\")\n",
        "    line = line.replace(\"-\", \" \") #replace hyphens with spaces\n",
        "    line = line.replace(\"\\t\", \" \")\n",
        "    line = line.replace(\"\\n\", \" \")\n",
        "    line = line.lower()\n",
        "\n",
        "    for char in line:\n",
        "        if char in 'qwertyuiopasdfghjklzxcvbnm ':\n",
        "            clean_line += char\n",
        "        else:\n",
        "            clean_line += ' '\n",
        "\n",
        "    clean_line = re.sub(' +',' ',clean_line) #delete extra spaces\n",
        "    if clean_line[0] == ' ':\n",
        "        clean_line = clean_line[1:]\n",
        "    return clean_line\n",
        "\n",
        "########################################################################\n",
        "# Synonym replacement\n",
        "# Replace n words in the sentence with synonyms from wordnet\n",
        "########################################################################\n",
        "\n",
        "#for the first time you use wordnet\n",
        "#import nltk\n",
        "#nltk.download('wordnet')\n",
        "from nltk.corpus import wordnet \n",
        "\n",
        "def synonym_replacement(words, n):\n",
        "\tnew_words = words.copy()\n",
        "\trandom_word_list = list(set([word for word in words if word not in stop_words]))\n",
        "\trandom.shuffle(random_word_list)\n",
        "\tnum_replaced = 0\n",
        "\tfor random_word in random_word_list:\n",
        "\t\tsynonyms = get_synonyms(random_word)\n",
        "\t\tif len(synonyms) >= 1:\n",
        "\t\t\tsynonym = random.choice(list(synonyms))\n",
        "\t\t\tnew_words = [synonym if word == random_word else word for word in new_words]\n",
        "\t\t\t#print(\"replaced\", random_word, \"with\", synonym)\n",
        "\t\t\tnum_replaced += 1\n",
        "\t\tif num_replaced >= n: #only replace up to n words\n",
        "\t\t\tbreak\n",
        "\n",
        "\t#this is stupid but we need it, trust me\n",
        "\tsentence = ' '.join(new_words)\n",
        "\tnew_words = sentence.split(' ')\n",
        "\n",
        "\treturn new_words\n",
        "\n",
        "def get_synonyms(word):\n",
        "\tsynonyms = set()\n",
        "\tfor syn in wordnet.synsets(word): \n",
        "\t\tfor l in syn.lemmas(): \n",
        "\t\t\tsynonym = l.name().replace(\"_\", \" \").replace(\"-\", \" \").lower()\n",
        "\t\t\tsynonym = \"\".join([char for char in synonym if char in ' qwertyuiopasdfghjklzxcvbnm'])\n",
        "\t\t\tsynonyms.add(synonym) \n",
        "\tif word in synonyms:\n",
        "\t\tsynonyms.remove(word)\n",
        "\treturn list(synonyms)\n",
        "\n",
        "########################################################################\n",
        "# Random deletion\n",
        "# Randomly delete words from the sentence with probability p\n",
        "########################################################################\n",
        "\n",
        "def random_deletion(words, p):\n",
        "\n",
        "\t#obviously, if there's only one word, don't delete it\n",
        "\tif len(words) == 1:\n",
        "\t\treturn words\n",
        "\n",
        "\t#randomly delete words with probability p\n",
        "\tnew_words = []\n",
        "\tfor word in words:\n",
        "\t\tr = random.uniform(0, 1)\n",
        "\t\tif r > p:\n",
        "\t\t\tnew_words.append(word)\n",
        "\n",
        "\t#if you end up deleting all words, just return a random word\n",
        "\tif len(new_words) == 0:\n",
        "\t\trand_int = random.randint(0, len(words)-1)\n",
        "\t\treturn [words[rand_int]]\n",
        "\n",
        "\treturn new_words\n",
        "\n",
        "########################################################################\n",
        "# Random swap\n",
        "# Randomly swap two words in the sentence n times\n",
        "########################################################################\n",
        "\n",
        "def random_swap(words, n):\n",
        "\tnew_words = words.copy()\n",
        "\tfor _ in range(n):\n",
        "\t\tnew_words = swap_word(new_words)\n",
        "\treturn new_words\n",
        "\n",
        "def swap_word(new_words):\n",
        "\trandom_idx_1 = random.randint(0, len(new_words)-1)\n",
        "\trandom_idx_2 = random_idx_1\n",
        "\tcounter = 0\n",
        "\twhile random_idx_2 == random_idx_1:\n",
        "\t\trandom_idx_2 = random.randint(0, len(new_words)-1)\n",
        "\t\tcounter += 1\n",
        "\t\tif counter > 3:\n",
        "\t\t\treturn new_words\n",
        "\tnew_words[random_idx_1], new_words[random_idx_2] = new_words[random_idx_2], new_words[random_idx_1] \n",
        "\treturn new_words\n",
        "\n",
        "########################################################################\n",
        "# Random insertion\n",
        "# Randomly insert n words into the sentence\n",
        "########################################################################\n",
        "\n",
        "def random_insertion(words, n):\n",
        "\tnew_words = words.copy()\n",
        "\tfor _ in range(n):\n",
        "\t\tadd_word(new_words)\n",
        "\treturn new_words\n",
        "\n",
        "def add_word(new_words):\n",
        "\tsynonyms = []\n",
        "\tcounter = 0\n",
        "\twhile len(synonyms) < 1:\n",
        "\t\trandom_word = new_words[random.randint(0, len(new_words)-1)]\n",
        "\t\tsynonyms = get_synonyms(random_word)\n",
        "\t\tcounter += 1\n",
        "\t\tif counter >= 10:\n",
        "\t\t\treturn\n",
        "\trandom_synonym = synonyms[0]\n",
        "\trandom_idx = random.randint(0, len(new_words)-1)\n",
        "\tnew_words.insert(random_idx, random_synonym)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLk4iZGYvUQN"
      },
      "source": [
        "def eda(sentence, alpha_sr=0.1, alpha_ri=0.1, alpha_rs=0.1, p_rd=0.1, num_aug=9):\n",
        "\t\n",
        "\tsentence = get_only_chars(sentence)\n",
        "\twords = sentence.split(' ')\n",
        "\twords = [word for word in words if word is not '']\n",
        "\tnum_words = len(words)\n",
        "\t\n",
        "\taugmented_sentences = []\n",
        "\tnum_new_per_technique = int(num_aug/4)+1\n",
        "\n",
        "\t#sr\n",
        "\tif (alpha_sr > 0):\n",
        "\t\tn_sr = max(1, int(alpha_sr*num_words))\n",
        "\t\tfor _ in range(num_new_per_technique):\n",
        "\t\t\ta_words = synonym_replacement(words, n_sr)\n",
        "\t\t\taugmented_sentences.append(' '.join(a_words))\n",
        "\n",
        "\t#ri\n",
        "\tif (alpha_ri > 0):\n",
        "\t\tn_ri = max(1, int(alpha_ri*num_words))\n",
        "\t\tfor _ in range(num_new_per_technique):\n",
        "\t\t\ta_words = random_insertion(words, n_ri)\n",
        "\t\t\taugmented_sentences.append(' '.join(a_words))\n",
        "\n",
        "\t#rs\n",
        "\tif (alpha_rs > 0):\n",
        "\t\tn_rs = max(1, int(alpha_rs*num_words))\n",
        "\t\tfor _ in range(num_new_per_technique):\n",
        "\t\t\ta_words = random_swap(words, n_rs)\n",
        "\t\t\taugmented_sentences.append(' '.join(a_words))\n",
        "\n",
        "\t#rd\n",
        "\tif (p_rd > 0):\n",
        "\t\tfor _ in range(num_new_per_technique):\n",
        "\t\t\ta_words = random_deletion(words, p_rd)\n",
        "\t\t\taugmented_sentences.append(' '.join(a_words))\n",
        "\n",
        "\taugmented_sentences = [get_only_chars(sentence) for sentence in augmented_sentences]\n",
        "\tshuffle(augmented_sentences)\n",
        "\n",
        "\t#trim so that we have the desired number of augmented sentences\n",
        "\tif num_aug >= 1:\n",
        "\t\taugmented_sentences = augmented_sentences[:num_aug]\n",
        "\telse:\n",
        "\t\tkeep_prob = num_aug / len(augmented_sentences)\n",
        "\t\taugmented_sentences = [s for s in augmented_sentences if random.uniform(0, 1) < keep_prob]\n",
        "\n",
        "\t#append the original sentence\n",
        "\taugmented_sentences.append(sentence)\n",
        "\n",
        "\treturn augmented_sentences"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "kgMo4RZUxCPP",
        "outputId": "e7498e1c-d1be-430f-a65c-3211edd825d3"
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_index</th>\n",
              "      <th>sentence</th>\n",
              "      <th>phrase ids</th>\n",
              "      <th>sentiment values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6681</th>\n",
              "      <td>6682</td>\n",
              "      <td>It 's got the brawn , but not the brains .</td>\n",
              "      <td>106881.0</td>\n",
              "      <td>0.31944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8685</th>\n",
              "      <td>8686</td>\n",
              "      <td>Just one problem : Fish out of water usually d...</td>\n",
              "      <td>146972.0</td>\n",
              "      <td>0.44444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7541</th>\n",
              "      <td>7542</td>\n",
              "      <td>A very long movie , dull in stretches , with e...</td>\n",
              "      <td>143420.0</td>\n",
              "      <td>0.19444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3535</th>\n",
              "      <td>3536</td>\n",
              "      <td>Director Juan Jose Campanella could have turne...</td>\n",
              "      <td>223149.0</td>\n",
              "      <td>0.93056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1566</th>\n",
              "      <td>1567</td>\n",
              "      <td>Writer-director 's Mehta 's effort has tons of...</td>\n",
              "      <td>47695.0</td>\n",
              "      <td>0.83333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      sentence_index  ... sentiment values\n",
              "6681            6682  ...          0.31944\n",
              "8685            8686  ...          0.44444\n",
              "7541            7542  ...          0.19444\n",
              "3535            3536  ...          0.93056\n",
              "1566            1567  ...          0.83333\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mca6Z06sTEi"
      },
      "source": [
        "# from eda import *\n",
        "simpler_series_df = train_df.copy()\n",
        "empty_series = { col:[] for col in train_df.columns.values}\n",
        "my_new_df = pd.DataFrame(data=empty_series)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hajx-ZU3sidO"
      },
      "source": [
        "simpler_series_df = train_df"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "eSYPGr7SxIO7",
        "outputId": "8e4067a1-c383-47e5-947c-5cadcd4ed283"
      },
      "source": [
        "simpler_series_df.head()"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_index</th>\n",
              "      <th>sentence</th>\n",
              "      <th>phrase ids</th>\n",
              "      <th>sentiment values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6681</th>\n",
              "      <td>6682</td>\n",
              "      <td>It 's got the brawn , but not the brains .</td>\n",
              "      <td>106881.0</td>\n",
              "      <td>0.31944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8685</th>\n",
              "      <td>8686</td>\n",
              "      <td>Just one problem : Fish out of water usually d...</td>\n",
              "      <td>146972.0</td>\n",
              "      <td>0.44444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7541</th>\n",
              "      <td>7542</td>\n",
              "      <td>A very long movie , dull in stretches , with e...</td>\n",
              "      <td>143420.0</td>\n",
              "      <td>0.19444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3535</th>\n",
              "      <td>3536</td>\n",
              "      <td>Director Juan Jose Campanella could have turne...</td>\n",
              "      <td>223149.0</td>\n",
              "      <td>0.93056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1566</th>\n",
              "      <td>1567</td>\n",
              "      <td>Writer-director 's Mehta 's effort has tons of...</td>\n",
              "      <td>47695.0</td>\n",
              "      <td>0.83333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      sentence_index  ... sentiment values\n",
              "6681            6682  ...          0.31944\n",
              "8685            8686  ...          0.44444\n",
              "7541            7542  ...          0.19444\n",
              "3535            3536  ...          0.93056\n",
              "1566            1567  ...          0.83333\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4LNlCnKuTW0"
      },
      "source": [
        "max_sentence_ids = simpler_series_df.sentence_index.max()\n",
        "alpha_sr = 0.0\n",
        "alpha_ri=0.0\n",
        "alpha_rs=0.2\n",
        "alpha_rd=0.2\n",
        "num_aug=5\n",
        "\n",
        "for idx in simpler_series_df.itertuples():\n",
        "    # print(idx)\n",
        "    sentence = idx.sentence\n",
        "    aug_sentences = eda(sentence, alpha_sr=alpha_sr, alpha_ri=alpha_ri, alpha_rs=alpha_rs, p_rd=alpha_rd, num_aug=num_aug)\n",
        "    for aug_sentence in aug_sentences:\n",
        "        max_sentence_ids += 1\n",
        "        my_new_df.loc[len(my_new_df)] = [max_sentence_ids,aug_sentence, np.int(idx._3), idx._4 ]"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "-OZnjPrNxqrs",
        "outputId": "297461de-eaaf-4a47-dab9-f427785313bb"
      },
      "source": [
        "my_new_df"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_index</th>\n",
              "      <th>sentence</th>\n",
              "      <th>phrase ids</th>\n",
              "      <th>sentiment values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11855.0</td>\n",
              "      <td>it s got brains brawn but not the the</td>\n",
              "      <td>106881.0</td>\n",
              "      <td>0.31944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11856.0</td>\n",
              "      <td>it s got the but not the brains</td>\n",
              "      <td>106881.0</td>\n",
              "      <td>0.31944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>11857.0</td>\n",
              "      <td>it s got but not the</td>\n",
              "      <td>106881.0</td>\n",
              "      <td>0.31944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11858.0</td>\n",
              "      <td>it s got the brawn the not but brains</td>\n",
              "      <td>106881.0</td>\n",
              "      <td>0.31944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11859.0</td>\n",
              "      <td>it s got the brawn but not the brains</td>\n",
              "      <td>106881.0</td>\n",
              "      <td>0.31944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48915</th>\n",
              "      <td>56995.0</td>\n",
              "      <td>there nothing exactly wrong here but there s n...</td>\n",
              "      <td>188845.0</td>\n",
              "      <td>0.33333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48916</th>\n",
              "      <td>56996.0</td>\n",
              "      <td>there s nothing exactly wrong here that s near...</td>\n",
              "      <td>188845.0</td>\n",
              "      <td>0.33333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48917</th>\n",
              "      <td>56997.0</td>\n",
              "      <td>there s nothing nearly wrong that but there s ...</td>\n",
              "      <td>188845.0</td>\n",
              "      <td>0.33333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48918</th>\n",
              "      <td>56998.0</td>\n",
              "      <td>there s nothing exactly wrong but there s not ...</td>\n",
              "      <td>188845.0</td>\n",
              "      <td>0.33333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48919</th>\n",
              "      <td>56999.0</td>\n",
              "      <td>there s nothing exactly wrong here but there s...</td>\n",
              "      <td>188845.0</td>\n",
              "      <td>0.33333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>48920 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       sentence_index  ... sentiment values\n",
              "0             11855.0  ...          0.31944\n",
              "1             11856.0  ...          0.31944\n",
              "2             11857.0  ...          0.31944\n",
              "3             11858.0  ...          0.31944\n",
              "4             11859.0  ...          0.31944\n",
              "...               ...  ...              ...\n",
              "48915         56995.0  ...          0.33333\n",
              "48916         56996.0  ...          0.33333\n",
              "48917         56997.0  ...          0.33333\n",
              "48918         56998.0  ...          0.33333\n",
              "48919         56999.0  ...          0.33333\n",
              "\n",
              "[48920 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqFEflFHuqDy"
      },
      "source": [
        "my_new_df = my_new_df.sample(frac = 1)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqBzNONWxtqK"
      },
      "source": [
        "my_new_df.to_csv(\"StanfordAugmented.csv\", index = False, sep = \"|\")"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpWRHzOTxv1P"
      },
      "source": [
        "my_new_df = my_new_df.append(train_df, ignore_index = True)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpYVYBg9x2C_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVhp-7plyDhO"
      },
      "source": [
        "\n",
        "## **Augmenting with Back_Translate**\n",
        "In this method we make a translate from source English sentence to a sentence in random language and then back into English. We create a dataframe of around 4000 samples and append it back to the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9b5jlHtJyFd-"
      },
      "source": [
        "translator = googletrans.Translator()\n",
        "\n",
        "def back_translate(sentence):\n",
        "    available_langs = list(googletrans.LANGUAGES.keys()) \n",
        "    trans_lang = random.choice(available_langs) \n",
        "    translations = translator.translate(sentence, dest=trans_lang) \n",
        "    t_text = [t.text for t in translations]\n",
        "    translations_en_random = translator.translate(t_text, src=trans_lang, dest='en') \n",
        "    en_text = [t.text for t in translations_en_random]\n",
        "    return en_text"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2auxXF5yKLu"
      },
      "source": [
        "max_sentence_ids=simpler_series_df[\"sentence_index\"].max()\n",
        "for idx in my_new_df[2000:6000].itertuples():\n",
        "    sentence = idx.sentence\n",
        "    aug_sentence = back_translate([sentence])[0]\n",
        "    max_sentence_ids += 1\n",
        "    simpler_series_df.loc[len(simpler_series_df)] = [max_sentence_ids,aug_sentence, np.int(idx._3), idx._4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjPMvPE5zT_O"
      },
      "source": [
        "simpler_series_df.to_csv(\"StanfordTranslate.csv\", index = False, sep = \"|\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbXOj7uvzirj"
      },
      "source": [
        "my_new_df = my_new_df.append(train_df, ignore_index = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfUPXdYHzlwu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wN4W9Q7zoGD"
      },
      "source": [
        "## **Range expansion**\n",
        "The sentiment scores are floats between [0,1] so we convert this to equivalent integers between 0 and 24(i.e 25 different classes)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZnU3NYWztsO"
      },
      "source": [
        "my_new_df[\"label\"] = 0\n",
        "\n",
        "def quantize_predictions(score_val):\n",
        "    return np.floor(score_val * 24)\n",
        "\n",
        "my_new_df.loc[:,\"label\"] = my_new_df.loc[:,\"sentiment score\"].apply(quantize_predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2z5z-yk_z8e-"
      },
      "source": [
        "my_new_df[\"sentence_index\"] = my_new_df[\"sentence_index\"].astype('int')\n",
        "my_new_df[\"Phrase_Id\"] = my_new_df[\"phrase ida\"].astype('int')\n",
        "my_new_df[\"label\"] = my_new_df[\"label\"].astype('int')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgwaRagM0Lqk"
      },
      "source": [
        "my_new_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aw1MNfvk0oh4"
      },
      "source": [
        "my_new_df.to_csv(\"StanFullTrain.csv\", index = False, sep = \"|\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUgfDZuM0pOi"
      },
      "source": [
        "## **Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7F0WxI240xLt"
      },
      "source": [
        "# Import Library\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import torch, torchtext\n",
        "from torchtext import data \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Manual Seed\n",
        "SEED = 43\n",
        "torch.manual_seed(SEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sxPzjmb0996"
      },
      "source": [
        "my_new_df = pd.read_csv(\"StanFullTrain.csv\", sep=\"|\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etsp9N790_qq"
      },
      "source": [
        "num_bins = 25\n",
        "\n",
        "colors = ['green'] \n",
        "plt.hist(my_new_df.label, density = False, bins = 25, histtype = 'bar', color = colors, label = colors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBwnCl821V9q"
      },
      "source": [
        "Sentence = data.Field(sequential = True, tokenize = 'spacy', batch_first =True, include_lengths=True)\n",
        "Label = data.LabelField(tokenize ='spacy', is_target=True, batch_first =True, sequential =False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALVglAZ71Y-7"
      },
      "source": [
        "fields = [('sentence', Sentence),('label',Label)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4pUzcwQ1bRi"
      },
      "source": [
        "example = [data.Example.fromlist([my_new_df.sentence[i],my_new_df.label[i]], fields) for i in range(my_new_df.shape[0])] \n",
        "\n",
        "stanTreeDataset = data.Dataset(example, fields)\n",
        "(train, valid) = stanTreeDataset.split(split_ratio=[0.85, 0.15], random_state=random.seed(SEED))\n",
        "Sentence.build_vocab(train)\n",
        "Label.build_vocab(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwQMYfPF1fGB"
      },
      "source": [
        "(len(train), len(valid))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LddtK8AX1h7-"
      },
      "source": [
        "print('Size of input vocab : ', len(Sentence.vocab))\n",
        "print('Size of label vocab : ', len(Label.vocab))\n",
        "print('Top 10 words appreared repeatedly :', list(Sentence.vocab.freqs.most_common(10)))\n",
        "print('Labels : ', Label.vocab.stoi)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbQ2f7Al1kN1"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBz9dcf81mSR"
      },
      "source": [
        "train_iterator, valid_iterator = data.BucketIterator.splits((train, valid), batch_size = 32, \n",
        "                                                            sort_key = lambda x: len(x.sentence),\n",
        "                                                            sort_within_batch=True, device = device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EOcbV8L1ouJ"
      },
      "source": [
        "next(iter(train_iterator))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YspsraVl1reJ"
      },
      "source": [
        "import os, pickle\n",
        "with open('tokenizer.pkl', 'wb') as tokens: \n",
        "    pickle.dump(Sentence.vocab.stoi, tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUdVyUS21xc5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}